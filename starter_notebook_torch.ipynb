{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e74eba",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d0d8b5d4",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -Uq wandb tqdm torchsummary\n",
    "!pip install -Uq randomname # for generating funky names for the sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "468358eb",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "69990fd2",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwandb_fc\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/opt/conda/lib/python3.8/site-packages/IPython/html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adrishd/taco-baseline/runs/fpwscphp\" target=\"_blank\">fanciful-tree-110</a></strong> to <a href=\"https://wandb.ai/adrishd/taco-baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact taco:pytorch, 2507.15MB. 1503 files... Done. 0:0:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 643... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fanciful-tree-110</strong>: <a href=\"https://wandb.ai/adrishd/taco-baseline/runs/fpwscphp\" target=\"_blank\">https://wandb.ai/adrishd/taco-baseline/runs/fpwscphp</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211209_234708-fpwscphp/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "# Define wandb username, project name and dataset path\n",
    "wandb_username = \"adrishd\"\n",
    "wandb_project = \"taco-baseline\"\n",
    "dataset_artifact = 'adrishd/taco/taco:pytorch'\n",
    "\n",
    "# Downloading dataset\n",
    "# use root parameter in artifacts.download(root=<custom_path>)\n",
    "# to specify download directory. else download in the current directory.\n",
    "with wandb.init(entity=wandb_username, project=wandb_project) as run:\n",
    "    artifact = run.use_artifact(dataset_artifact, type='dataset')\n",
    "    artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0276ebf",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "775437a6",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "outputs": [],
   "source": [
    "import randomname\n",
    "import tacoloader\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import torchsummary\n",
    "import time\n",
    "import tqdm as tqdm\n",
    "import torchvision\n",
    "\n",
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b9cffb",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "3ef66ee1",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "outputs": [],
   "source": [
    "h, w, c = 512, 512, 3 # height, width and channel of images\n",
    "# Use torchvision.transpose.Compose to compose multiple transformations\n",
    "# together. Refer to: https://pytorch.org/vision/stable/transforms.html\n",
    "transform = torchvision.transforms.Resize(\n",
    "        (h, w),\n",
    "        torchvision.transforms.InterpolationMode.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e78ca3",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6b2d2a07",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "outputs": [],
   "source": [
    "# Constants in the training pipeline\n",
    "train_batch_size = 10\n",
    "test_batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b067bf",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "115efb09",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE! Installing ujson may make loading annotations faster.\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# By default an LRU cache is used for storing the last recently loaded image\n",
    "# and re-using that in the next epoch.\n",
    "# To store `all` the loaded images in memory and reuse them in the next epochs\n",
    "# set cache_fn=taco_loader.cache_fn in tacoloader.load_dataset(...)\n",
    "# an user can also increase the size of LRU cache, by\n",
    "# setting cache_fn=functools.lru_cache(maxsize=<int size>) in\n",
    "# tacoloader.load_dataset(...)\n",
    "\n",
    "dataset, collate_fn = tacoloader.load_dataset(\n",
    "  artifact_dir,\n",
    "  tacoloader.Environment.TORCH,\n",
    "  transform_fn=transform\n",
    ")\n",
    "\n",
    "# Splitting Dataset to 80%-20% for training and testing, respectively\n",
    "train_split = 0.8\n",
    "dataset_size = len(dataset)\n",
    "indices = range(dataset_size)\n",
    "train_indices = indices[:int(train_split * dataset_size)]\n",
    "test_indices = indices[int(train_split * dataset_size) + 1:]\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06845c28",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "3e09efda",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "outputs": [],
   "source": [
    "# Creating Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    collate_fn=dataset.collate_fn,\n",
    "    num_workers=6,\n",
    "    shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    collate_fn=dataset.collate_fn,\n",
    "    num_workers=6,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a538f6",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "eee8b1da",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "outputs": [],
   "source": [
    "def viz_mask(image, pred_mask, true_mask):\n",
    "    # Visualize segmentation mask on W&B dashboard\n",
    "    # image: torch tensor of dim [c, h, w]\n",
    "    # pred_mask: detached torch tensor of dim [h, w]\n",
    "    # true_mask: torch tensor of dim [h, w]\n",
    "    pred_labels = torch.unique(pred_mask).cpu().numpy().tolist()\n",
    "    predicted_class_labels = {\n",
    "        i : x for i, x in enumerate(dataset.get_categories(pred_labels))\n",
    "    }\n",
    "    gt_labels = torch.unique(true_mask).cpu().numpy().tolist()\n",
    "    ground_truth_labels = {\n",
    "        i: x for i, x in enumerate(dataset.get_categories(gt_labels))\n",
    "    }\n",
    "    wandb_image = wandb.Image(image.cpu(), masks={\n",
    "        \"prediction\": {\n",
    "            \"mask_data\": pred_mask.squeeze().cpu().numpy(),\n",
    "            \"class_labels\": predicted_class_labels\n",
    "        },\n",
    "        \"ground_truth\": {\n",
    "            \"mask_data\": true_mask.cpu().numpy(),\n",
    "            \"class_labels\": ground_truth_labels\n",
    "        }\n",
    "    })\n",
    "    wandb.log({\"semantic_segmentation\" : wandb_image})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b8cd6f",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c0450e91",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "source": [
    "## Model Design and Implementations\n",
    "### Starter Code: Helper Modules for UNet Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49582101",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "981805e0",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function for getting activation functions\n",
    "# from torch.nn given the function name.\n",
    "# activations with inplace operations, are enabled\n",
    "# by default.\n",
    "import inspect\n",
    "import functools\n",
    "def get_activation_fn(fn_name):\n",
    "    fn = getattr(torch.nn, fn_name)\n",
    "    isinplace = \"inplace\" in inspect.signature(fn).parameters\n",
    "    if isinplace:\n",
    "        fn = functools.partial(fn, inplace=True)\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7731e992",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "e7562ca0",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "outputs": [],
   "source": [
    "# Dummy baseline UNet model based on:\n",
    "# https://github.com/xiaopeng-liao/Pytorch-UNet/blob/master/unet/unet_parts.py\n",
    "class double_conv(torch.nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch, activation_fn_name):\n",
    "        super(double_conv, self).__init__()\n",
    "        activation_fn = get_activation_fn(activation_fn_name)\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            torch.nn.BatchNorm2d(out_ch),\n",
    "            activation_fn(),\n",
    "            torch.nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            torch.nn.BatchNorm2d(out_ch),\n",
    "            activation_fn()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class inconv(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation_fn):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch, activation_fn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class down(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation_fn):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            double_conv(in_ch, out_ch, activation_fn)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class up(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation_fn, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "        if bilinear:\n",
    "            self.up = torch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = torch.nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch, activation_fn)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffX = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
    "                        diffY // 2, diffY - diffY//2))\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class outconv(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_ch, out_ch, 1)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d91ec4e3",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "586b1a29",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, config):\n",
    "        super(UNet, self).__init__()\n",
    "        mid_channels = config[\"unet_channels\"]\n",
    "        activation_fn = config[\"activation_fn\"]\n",
    "        self.inc = inconv(n_channels,\n",
    "                          mid_channels,\n",
    "                          activation_fn)\n",
    "        self.down1 = down(mid_channels,\n",
    "                          mid_channels * 2,\n",
    "                          activation_fn)\n",
    "        self.down2 = down(mid_channels * 2,\n",
    "                          mid_channels * 4,\n",
    "                          activation_fn)\n",
    "        self.down3 = down(mid_channels * 4,\n",
    "                          mid_channels * 8,\n",
    "                          activation_fn)\n",
    "        self.down4 = down(mid_channels * 8,\n",
    "                          mid_channels * 8,\n",
    "                          activation_fn)\n",
    "        self.up1 = up(mid_channels * 16,\n",
    "                      mid_channels * 4,\n",
    "                      activation_fn,\n",
    "                      bilinear=config[\"bilinear\"])\n",
    "        self.up2 = up(mid_channels * 8,\n",
    "                      mid_channels * 2,\n",
    "                      activation_fn,\n",
    "                      bilinear=config[\"bilinear\"])\n",
    "        self.up3 = up(mid_channels * 4,\n",
    "                      mid_channels,\n",
    "                      activation_fn,\n",
    "                      bilinear=config[\"bilinear\"])\n",
    "        self.up4 = up(mid_channels * 2,\n",
    "                      mid_channels,\n",
    "                      activation_fn,\n",
    "                      bilinear=config[\"bilinear\"])\n",
    "        self.outc = outconv(mid_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1486a40",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "1b7bb80c",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7def43fe",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "108c7cd5",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "source": [
    "### Training, Logging, Finding Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "845783aa",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a3dfa328",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 1dd7a9l1\n",
      "Sweep URL: https://wandb.ai/adrishd/taco-baseline/sweeps/1dd7a9l1\n"
     ]
    }
   ],
   "source": [
    "# Using wandb's hyperparameter optimization framework sweeps\n",
    "# More information can be found here: https://docs.wandb.ai/guides/sweeps\n",
    "sweep_name = randomname.get_name()\n",
    "sweep_config = {\n",
    "    \"name\" : sweep_name,\n",
    "    \"method\" : \"bayes\",\n",
    "    \"metric\" : {\n",
    "        \"name\": \"mean_iou\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"parameters\" : {\n",
    "        \"epochs\" : {\n",
    "            \"values\": [0, 1, 3, 5]\n",
    "        },\n",
    "        \"lr\" : {\n",
    "            \"min\": 1e-4,\n",
    "            \"max\": 1e-2\n",
    "        },\n",
    "        \"activation_fn\" : {\n",
    "            \"values\" : [\"ReLU\", \"LeakyReLU\", \"PReLU\"]\n",
    "        },\n",
    "        \"unet_channels\" : {\n",
    "            \"values\" : [8, 16, 32]\n",
    "        },\n",
    "        \"bilinear\" : {\n",
    "            \"values\" : [True, False]\n",
    "        },\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(\n",
    "    sweep_config,\n",
    "    entity=wandb_username,\n",
    "    project=wandb_project\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49fc81d6",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7994356c",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy metrics\n",
    "\n",
    "def pixel_accuracy(pred, ground):\n",
    "    eqmap = torch.eq(pred, ground).int()\n",
    "    return eqmap.sum().float() / eqmap.numel()\n",
    "\n",
    "# mIOU based on: https://stackoverflow.com/questions/62461379/multiclass-semantic-segmentation-model-evaluation\n",
    "def mIOU(pred, label, num_classes):\n",
    "    iou_list = list()\n",
    "    present_iou_list = list()\n",
    "    pred = pred.view(-1)\n",
    "    label = label.view(-1)\n",
    "    for sem_class in range(num_classes):\n",
    "        pred_inds = (pred == sem_class)\n",
    "        target_inds = (label == sem_class)\n",
    "        if target_inds.long().sum() == 0:\n",
    "            iou_now = torch.nan\n",
    "        else: \n",
    "            intersection_now = (pred_inds[target_inds]).long().sum()\n",
    "            union_now = pred_inds.long().sum() + target_inds.long().sum() - intersection_now\n",
    "            iou_now = intersection_now.float() / union_now.float()\n",
    "            present_iou_list.append(iou_now)\n",
    "        iou_list.append(iou_now)\n",
    "    return torch.mean(torch.stack(present_iou_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6e952f8",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "638d18d7",
     "kernelId": "df2e43e8-9ac2-45ab-80f9-e4c0e060a469"
    }
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    with wandb.init(entity=wandb_username, project=wandb_project) as run:\n",
    "        config = wandb.config\n",
    "        num_classes = dataset.len_categories\n",
    "        unet = UNet(3, num_classes, config).to(device)\n",
    "        optim = torch.optim.Adam(unet.parameters(), lr=config[\"lr\"])\n",
    "        for x in tqdm.tqdm(range(config[\"epochs\"])):\n",
    "            bar = tqdm.tqdm(train_loader)\n",
    "            for data in bar:\n",
    "                optim.zero_grad()\n",
    "                segmask = unet(data.images.to(device))\n",
    "                loss = loss_fn(segmask, data.masks.to(device).long())\n",
    "                loss.backward()\n",
    "                bar.set_description(\"Loss: %f\" % loss.detach().cpu())\n",
    "                wandb.log({\"loss\": loss.detach().cpu()})\n",
    "                optim.step()\n",
    "        test_bar = tqdm.tqdm(test_loader, position=0)\n",
    "        with torch.no_grad():\n",
    "            for data in test_bar:\n",
    "                segmask = unet(data.images.to(device))\n",
    "                mask = torch.argmax(segmask, dim=1).detach().cpu()\n",
    "                acc = pixel_accuracy(mask, data.masks)\n",
    "                miou = mIOU(mask, data.masks, num_classes).numpy()\n",
    "                test_bar.set_description(\"Acc: %.2f\" % acc)\n",
    "                wandb.log({\n",
    "                    \"mean_pixel_accuracy\": acc,\n",
    "                    \"mean_iou\": miou})\n",
    "        # Draw one sample and visualize the mask for each sweep\n",
    "        sample = test_dataset[0]\n",
    "        segmask = unet(sample.image.unsqueeze(0).to(device))\n",
    "        mask = torch.argmax(segmask, dim=1).detach().squeeze()\n",
    "        viz_mask(sample.image, mask, sample.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7038f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3zb4lf5l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: PReLU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbilinear: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.007958165896036953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunet_channels: 32\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adrishd/taco-baseline/runs/3zb4lf5l\" target=\"_blank\">quiet-sweep-1</a></strong> to <a href=\"https://wandb.ai/adrishd/taco-baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/adrishd/taco-baseline/sweeps/1dd7a9l1\" target=\"_blank\">https://wandb.ai/adrishd/taco-baseline/sweeps/1dd7a9l1</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "Acc: 0.00: 100%|██████████| 100/100 [00:40<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 719... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>mean_iou</td><td>▄▁▂▃▅▂▃▃▁▄▂▁▅▁▁▂▃▁▁▂▁▃▂▂▄▂▁▁▁▇▁▂▆▂█▁▁▆▁▂</td></tr><tr><td>mean_pixel_accuracy</td><td>▂▁▁▂▂▁▂▂▁▃▁▁▄▁▁▂▁▁▁▁▁▂▁▂▂▁▂▁▁▇▁▂▅▂▅▁▁█▁▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>mean_iou</td><td>0.00117</td></tr><tr><td>mean_pixel_accuracy</td><td>0.00051</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 3 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">quiet-sweep-1</strong>: <a href=\"https://wandb.ai/adrishd/taco-baseline/runs/3zb4lf5l\" target=\"_blank\">https://wandb.ai/adrishd/taco-baseline/runs/3zb4lf5l</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211209_234801-3zb4lf5l/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hi3mp21p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: LeakyReLU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbilinear: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0027793193660785873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunet_channels: 32\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adrishd/taco-baseline/runs/hi3mp21p\" target=\"_blank\">devoted-sweep-2</a></strong> to <a href=\"https://wandb.ai/adrishd/taco-baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/adrishd/taco-baseline/sweeps/1dd7a9l1\" target=\"_blank\">https://wandb.ai/adrishd/taco-baseline/sweeps/1dd7a9l1</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/120 [00:00<?, ?it/s]\u001b[A\n",
      "Loss: 4.096766:   0%|          | 0/120 [00:05<?, ?it/s]\u001b[A\n",
      "Loss: 4.096766:   1%|          | 1/120 [00:05<11:37,  5.86s/it]\u001b[A\n",
      "Loss: 4.094779:   1%|          | 1/120 [00:06<11:37,  5.86s/it]\u001b[A\n",
      "Loss: 4.094779:   2%|▏         | 2/120 [00:06<05:12,  2.65s/it]\u001b[A\n",
      "Loss: 4.087400:   2%|▏         | 2/120 [00:06<05:12,  2.65s/it]\u001b[A\n",
      "Loss: 4.087400:   2%|▎         | 3/120 [00:06<03:15,  1.67s/it]\u001b[A\n",
      "Loss: 4.083712:   2%|▎         | 3/120 [00:07<03:15,  1.67s/it]\u001b[A\n",
      "Loss: 4.083712:   3%|▎         | 4/120 [00:07<02:15,  1.17s/it]\u001b[A\n",
      "Loss: 4.077662:   3%|▎         | 4/120 [00:07<02:15,  1.17s/it]\u001b[A\n",
      "Loss: 4.077662:   4%|▍         | 5/120 [00:07<01:42,  1.12it/s]\u001b[A\n",
      "Loss: 4.071162:   4%|▍         | 5/120 [00:07<01:42,  1.12it/s]\u001b[A\n",
      "Loss: 4.071162:   5%|▌         | 6/120 [00:07<01:22,  1.38it/s]\u001b[A\n",
      "Loss: 4.062944:   5%|▌         | 6/120 [00:11<01:22,  1.38it/s]\u001b[A\n",
      "Loss: 4.062944:   6%|▌         | 7/120 [00:11<02:56,  1.56s/it]\u001b[A\n",
      "Loss: 4.054215:   6%|▌         | 7/120 [00:11<02:56,  1.56s/it]\u001b[A\n",
      "Loss: 4.054215:   7%|▋         | 8/120 [00:11<02:13,  1.19s/it]\u001b[A\n",
      "Loss: 4.043564:   7%|▋         | 8/120 [00:12<02:13,  1.19s/it]\u001b[A\n",
      "Loss: 4.043564:   8%|▊         | 9/120 [00:12<01:45,  1.06it/s]\u001b[A\n",
      "Loss: 4.038876:   8%|▊         | 9/120 [00:12<01:45,  1.06it/s]\u001b[A\n",
      "Loss: 4.038876:   8%|▊         | 10/120 [00:12<01:25,  1.29it/s]\u001b[A\n",
      "Loss: 4.052401:   8%|▊         | 10/120 [00:12<01:25,  1.29it/s]\u001b[A\n",
      "Loss: 4.052401:   9%|▉         | 11/120 [00:12<01:12,  1.51it/s]\u001b[A\n",
      "Loss: 4.023515:   9%|▉         | 11/120 [00:13<01:12,  1.51it/s]\u001b[A\n",
      "Loss: 4.023515:  10%|█         | 12/120 [00:13<01:02,  1.73it/s]\u001b[A\n",
      "Loss: 4.013043:  10%|█         | 12/120 [00:16<01:02,  1.73it/s]\u001b[A\n",
      "Loss: 4.013043:  11%|█         | 13/120 [00:16<02:41,  1.51s/it]\u001b[A\n",
      "Loss: 3.999823:  11%|█         | 13/120 [00:17<02:41,  1.51s/it]\u001b[A\n",
      "Loss: 3.999823:  12%|█▏        | 14/120 [00:17<02:03,  1.17s/it]\u001b[A\n",
      "Loss: 3.996757:  12%|█▏        | 14/120 [00:17<02:03,  1.17s/it]\u001b[A\n",
      "Loss: 3.996757:  12%|█▎        | 15/120 [00:17<01:38,  1.07it/s]\u001b[A\n",
      "Loss: 4.000390:  12%|█▎        | 15/120 [00:18<01:38,  1.07it/s]\u001b[A\n",
      "Loss: 4.000390:  13%|█▎        | 16/120 [00:18<01:20,  1.30it/s]\u001b[A\n",
      "Loss: 3.971649:  13%|█▎        | 16/120 [00:18<01:20,  1.30it/s]\u001b[A\n",
      "Loss: 3.971649:  14%|█▍        | 17/120 [00:18<01:07,  1.52it/s]\u001b[A\n",
      "Loss: 3.952749:  14%|█▍        | 17/120 [00:18<01:07,  1.52it/s]\u001b[A\n",
      "Loss: 3.952749:  15%|█▌        | 18/120 [00:18<00:59,  1.72it/s]\u001b[A\n",
      "Loss: 3.967257:  15%|█▌        | 18/120 [00:21<00:59,  1.72it/s]\u001b[A\n",
      "Loss: 3.967257:  16%|█▌        | 19/120 [00:21<02:04,  1.24s/it]\u001b[A\n",
      "Loss: 3.936841:  16%|█▌        | 19/120 [00:22<02:04,  1.24s/it]\u001b[A\n",
      "Loss: 3.936841:  17%|█▋        | 20/120 [00:22<01:38,  1.02it/s]\u001b[A\n",
      "Loss: 3.940791:  17%|█▋        | 20/120 [00:23<01:38,  1.02it/s]\u001b[A\n",
      "Loss: 3.940791:  18%|█▊        | 21/120 [00:23<01:49,  1.10s/it]\u001b[A\n",
      "Loss: 3.904982:  18%|█▊        | 21/120 [00:23<01:49,  1.10s/it]\u001b[A\n",
      "Loss: 3.904982:  18%|█▊        | 22/120 [00:23<01:27,  1.12it/s]\u001b[A\n",
      "Loss: 3.895577:  18%|█▊        | 22/120 [00:24<01:27,  1.12it/s]\u001b[A\n",
      "Loss: 3.895577:  19%|█▉        | 23/120 [00:24<01:11,  1.35it/s]\u001b[A\n",
      "Loss: 3.879858:  19%|█▉        | 23/120 [00:24<01:11,  1.35it/s]\u001b[A\n",
      "Loss: 3.879858:  20%|██        | 24/120 [00:24<01:01,  1.57it/s]\u001b[A\n",
      "Loss: 3.866546:  20%|██        | 24/120 [00:26<01:01,  1.57it/s]\u001b[A\n",
      "Loss: 3.866546:  21%|██        | 25/120 [00:26<01:42,  1.08s/it]\u001b[A\n",
      "Loss: 3.852208:  21%|██        | 25/120 [00:27<01:42,  1.08s/it]\u001b[A\n",
      "Loss: 3.852208:  22%|██▏       | 26/120 [00:27<01:22,  1.15it/s]\u001b[A\n",
      "Loss: 3.841935:  22%|██▏       | 26/120 [00:28<01:22,  1.15it/s]\u001b[A\n",
      "Loss: 3.841935:  22%|██▎       | 27/120 [00:28<01:47,  1.15s/it]\u001b[A\n",
      "Loss: 3.843004:  22%|██▎       | 27/120 [00:29<01:47,  1.15s/it]\u001b[A\n",
      "Loss: 3.843004:  23%|██▎       | 28/120 [00:29<01:24,  1.08it/s]\u001b[A\n",
      "Loss: 3.817633:  23%|██▎       | 28/120 [00:29<01:24,  1.08it/s]\u001b[A\n",
      "Loss: 3.817633:  24%|██▍       | 29/120 [00:29<01:09,  1.30it/s]\u001b[A\n",
      "Loss: 3.791956:  24%|██▍       | 29/120 [00:30<01:09,  1.30it/s]\u001b[A\n",
      "Loss: 3.791956:  25%|██▌       | 30/120 [00:30<00:59,  1.52it/s]\u001b[A\n",
      "Loss: 3.774438:  25%|██▌       | 30/120 [00:32<00:59,  1.52it/s]\u001b[A\n",
      "Loss: 3.774438:  26%|██▌       | 31/120 [00:32<01:34,  1.06s/it]\u001b[A\n",
      "Loss: 3.756374:  26%|██▌       | 31/120 [00:32<01:34,  1.06s/it]\u001b[A\n",
      "Loss: 3.756374:  27%|██▋       | 32/120 [00:32<01:15,  1.16it/s]\u001b[A\n",
      "Loss: 3.750684:  27%|██▋       | 32/120 [00:34<01:15,  1.16it/s]\u001b[A\n",
      "Loss: 3.750684:  28%|██▊       | 33/120 [00:34<01:41,  1.17s/it]\u001b[A\n",
      "Loss: 3.723905:  28%|██▊       | 33/120 [00:34<01:41,  1.17s/it]\u001b[A\n",
      "Loss: 3.723905:  28%|██▊       | 34/120 [00:34<01:20,  1.07it/s]\u001b[A\n",
      "Loss: 3.713482:  28%|██▊       | 34/120 [00:35<01:20,  1.07it/s]\u001b[A\n",
      "Loss: 3.713482:  29%|██▉       | 35/120 [00:35<01:05,  1.29it/s]\u001b[A\n",
      "Loss: 3.697322:  29%|██▉       | 35/120 [00:35<01:05,  1.29it/s]\u001b[A\n",
      "Loss: 3.697322:  30%|███       | 36/120 [00:35<00:55,  1.51it/s]\u001b[A\n",
      "Loss: 3.685020:  30%|███       | 36/120 [00:36<00:55,  1.51it/s]\u001b[A\n",
      "Loss: 3.685020:  31%|███       | 37/120 [00:36<00:52,  1.57it/s]\u001b[A\n",
      "Loss: 3.686608:  31%|███       | 37/120 [00:36<00:52,  1.57it/s]\u001b[A\n",
      "Loss: 3.686608:  32%|███▏      | 38/120 [00:36<00:46,  1.75it/s]\u001b[A\n",
      "Loss: 3.659620:  32%|███▏      | 38/120 [00:39<00:46,  1.75it/s]\u001b[A\n",
      "Loss: 3.659620:  32%|███▎      | 39/120 [00:39<01:38,  1.22s/it]\u001b[A\n",
      "Loss: 3.629913:  32%|███▎      | 39/120 [00:39<01:38,  1.22s/it]\u001b[A\n",
      "Loss: 3.629913:  33%|███▎      | 40/120 [00:39<01:17,  1.03it/s]\u001b[A\n",
      "Loss: 3.624593:  33%|███▎      | 40/120 [00:40<01:17,  1.03it/s]\u001b[A\n",
      "Loss: 3.624593:  34%|███▍      | 41/120 [00:40<01:02,  1.25it/s]\u001b[A\n",
      "Loss: 3.612621:  34%|███▍      | 41/120 [00:40<01:02,  1.25it/s]\u001b[A\n",
      "Loss: 3.612621:  35%|███▌      | 42/120 [00:40<00:52,  1.48it/s]\u001b[A\n",
      "Loss: 3.624164:  35%|███▌      | 42/120 [00:40<00:52,  1.48it/s]\u001b[A\n",
      "Loss: 3.624164:  36%|███▌      | 43/120 [00:40<00:45,  1.68it/s]\u001b[A\n",
      "Loss: 3.567499:  36%|███▌      | 43/120 [00:41<00:45,  1.68it/s]\u001b[A\n",
      "Loss: 3.567499:  37%|███▋      | 44/120 [00:41<00:40,  1.85it/s]\u001b[A\n",
      "Loss: 3.572472:  37%|███▋      | 44/120 [00:43<00:40,  1.85it/s]\u001b[A\n",
      "Loss: 3.572472:  38%|███▊      | 45/120 [00:43<01:24,  1.13s/it]\u001b[A\n",
      "Loss: 3.512372:  38%|███▊      | 45/120 [00:44<01:24,  1.13s/it]\u001b[A\n",
      "Loss: 3.512372:  38%|███▊      | 46/120 [00:44<01:14,  1.00s/it]\u001b[A\n",
      "Loss: 3.540118:  38%|███▊      | 46/120 [00:44<01:14,  1.00s/it]\u001b[A\n",
      "Loss: 3.540118:  39%|███▉      | 47/120 [00:44<01:00,  1.22it/s]\u001b[A\n",
      "Loss: 3.491709:  39%|███▉      | 47/120 [00:45<01:00,  1.22it/s]\u001b[A\n",
      "Loss: 3.491709:  40%|████      | 48/120 [00:45<00:50,  1.43it/s]\u001b[A\n",
      "Loss: 3.497788:  40%|████      | 48/120 [00:45<00:50,  1.43it/s]\u001b[A\n",
      "Loss: 3.497788:  41%|████      | 49/120 [00:45<00:43,  1.63it/s]\u001b[A\n",
      "Loss: 3.470994:  41%|████      | 49/120 [00:46<00:43,  1.63it/s]\u001b[A\n",
      "Loss: 3.470994:  42%|████▏     | 50/120 [00:46<00:38,  1.80it/s]\u001b[A\n",
      "Loss: 3.420153:  42%|████▏     | 50/120 [00:48<00:38,  1.80it/s]\u001b[A\n",
      "Loss: 3.420153:  42%|████▎     | 51/120 [00:48<01:11,  1.03s/it]\u001b[A\n",
      "Loss: 3.398694:  42%|████▎     | 51/120 [00:49<01:11,  1.03s/it]\u001b[A\n",
      "Loss: 3.398694:  43%|████▎     | 52/120 [00:50<01:24,  1.24s/it]\u001b[A\n",
      "Loss: 3.378350:  43%|████▎     | 52/120 [00:50<01:24,  1.24s/it]\u001b[A\n",
      "Loss: 3.378350:  44%|████▍     | 53/120 [00:50<01:06,  1.01it/s]\u001b[A\n",
      "Loss: 3.365919:  44%|████▍     | 53/120 [00:50<01:06,  1.01it/s]\u001b[A\n",
      "Loss: 3.365919:  45%|████▌     | 54/120 [00:50<00:53,  1.23it/s]\u001b[A\n",
      "Loss: 3.346771:  45%|████▌     | 54/120 [00:51<00:53,  1.23it/s]\u001b[A\n",
      "Loss: 3.346771:  46%|████▌     | 55/120 [00:51<00:44,  1.45it/s]\u001b[A\n",
      "Loss: 3.331557:  46%|████▌     | 55/120 [00:51<00:44,  1.45it/s]\u001b[A\n",
      "Loss: 3.331557:  47%|████▋     | 56/120 [00:51<00:38,  1.65it/s]\u001b[A\n",
      "Loss: 3.345384:  47%|████▋     | 56/120 [00:52<00:38,  1.65it/s]\u001b[A\n",
      "Loss: 3.345384:  48%|████▊     | 57/120 [00:52<00:42,  1.48it/s]\u001b[A\n",
      "Loss: 3.295039:  48%|████▊     | 57/120 [00:55<00:42,  1.48it/s]\u001b[A\n",
      "Loss: 3.295039:  48%|████▊     | 58/120 [00:55<01:24,  1.36s/it]\u001b[A\n",
      "Loss: 3.300379:  48%|████▊     | 58/120 [00:55<01:24,  1.36s/it]\u001b[A\n",
      "Loss: 3.300379:  49%|████▉     | 59/120 [00:55<01:05,  1.07s/it]\u001b[A\n",
      "Loss: 3.274008:  49%|████▉     | 59/120 [00:56<01:05,  1.07s/it]\u001b[A\n",
      "Loss: 3.274008:  50%|█████     | 60/120 [00:56<00:52,  1.15it/s]\u001b[A\n",
      "Loss: 3.239560:  50%|█████     | 60/120 [00:56<00:52,  1.15it/s]\u001b[A\n",
      "Loss: 3.239560:  51%|█████     | 61/120 [00:56<00:43,  1.37it/s]\u001b[A\n",
      "Loss: 3.276018:  51%|█████     | 61/120 [00:57<00:43,  1.37it/s]\u001b[A\n",
      "Loss: 3.276018:  52%|█████▏    | 62/120 [00:57<00:36,  1.58it/s]\u001b[A\n",
      "Loss: 3.286971:  52%|█████▏    | 62/120 [00:57<00:36,  1.58it/s]\u001b[A\n",
      "Loss: 3.286971:  52%|█████▎    | 63/120 [00:57<00:32,  1.74it/s]\u001b[A\n",
      "Loss: 3.280016:  52%|█████▎    | 63/120 [01:01<00:32,  1.74it/s]\u001b[A\n",
      "Loss: 3.280016:  53%|█████▎    | 64/120 [01:01<01:34,  1.69s/it]\u001b[A\n",
      "Loss: 3.264859:  53%|█████▎    | 64/120 [01:02<01:34,  1.69s/it]\u001b[A\n",
      "Loss: 3.264859:  54%|█████▍    | 65/120 [01:02<01:11,  1.30s/it]\u001b[A\n",
      "Loss: 3.192990:  54%|█████▍    | 65/120 [01:02<01:11,  1.30s/it]\u001b[A\n",
      "Loss: 3.192990:  55%|█████▌    | 66/120 [01:02<00:55,  1.03s/it]\u001b[A\n",
      "Loss: 3.233796:  55%|█████▌    | 66/120 [01:02<00:55,  1.03s/it]\u001b[A\n",
      "Loss: 3.233796:  56%|█████▌    | 67/120 [01:02<00:44,  1.18it/s]\u001b[A\n",
      "Loss: 3.225791:  56%|█████▌    | 67/120 [01:03<00:44,  1.18it/s]\u001b[A\n",
      "Loss: 3.225791:  57%|█████▋    | 68/120 [01:03<00:37,  1.40it/s]\u001b[A\n",
      "Loss: 3.189954:  57%|█████▋    | 68/120 [01:03<00:37,  1.40it/s]\u001b[A\n",
      "Loss: 3.189954:  57%|█████▊    | 69/120 [01:03<00:31,  1.60it/s]\u001b[A\n",
      "Loss: 3.180321:  57%|█████▊    | 69/120 [01:06<00:31,  1.60it/s]\u001b[A\n",
      "Loss: 3.180321:  58%|█████▊    | 70/120 [01:06<01:00,  1.21s/it]\u001b[A\n",
      "Loss: 3.193865:  58%|█████▊    | 70/120 [01:06<01:00,  1.21s/it]\u001b[A\n",
      "Loss: 3.193865:  59%|█████▉    | 71/120 [01:06<00:47,  1.03it/s]\u001b[A\n",
      "Loss: 3.197271:  59%|█████▉    | 71/120 [01:07<00:47,  1.03it/s]\u001b[A\n",
      "Loss: 3.197271:  60%|██████    | 72/120 [01:07<00:38,  1.25it/s]\u001b[A\n",
      "Loss: 3.253400:  60%|██████    | 72/120 [01:07<00:38,  1.25it/s]\u001b[A\n",
      "Loss: 3.253400:  61%|██████    | 73/120 [01:07<00:31,  1.47it/s]\u001b[A\n",
      "Loss: 3.188520:  61%|██████    | 73/120 [01:07<00:31,  1.47it/s]\u001b[A\n",
      "Loss: 3.188520:  62%|██████▏   | 74/120 [01:07<00:27,  1.67it/s]\u001b[A\n",
      "Loss: 3.193494:  62%|██████▏   | 74/120 [01:08<00:27,  1.67it/s]\u001b[A\n",
      "Loss: 3.193494:  62%|██████▎   | 75/120 [01:08<00:24,  1.84it/s]\u001b[A\n",
      "Loss: 3.213252:  62%|██████▎   | 75/120 [01:10<00:24,  1.84it/s]\u001b[A\n",
      "Loss: 3.213252:  63%|██████▎   | 76/120 [01:10<00:48,  1.09s/it]\u001b[A\n",
      "Loss: 3.147521:  63%|██████▎   | 76/120 [01:11<00:48,  1.09s/it]\u001b[A\n",
      "Loss: 3.147521:  64%|██████▍   | 77/120 [01:11<00:38,  1.13it/s]\u001b[A\n",
      "Loss: 3.220840:  64%|██████▍   | 77/120 [01:11<00:38,  1.13it/s]\u001b[A\n",
      "Loss: 3.220840:  65%|██████▌   | 78/120 [01:11<00:31,  1.35it/s]\u001b[A\n",
      "Loss: 3.208695:  65%|██████▌   | 78/120 [01:11<00:31,  1.35it/s]\u001b[A\n",
      "Loss: 3.208695:  66%|██████▌   | 79/120 [01:11<00:26,  1.56it/s]\u001b[A\n",
      "Loss: 3.187927:  66%|██████▌   | 79/120 [01:12<00:26,  1.56it/s]\u001b[A\n",
      "Loss: 3.187927:  67%|██████▋   | 80/120 [01:12<00:23,  1.74it/s]\u001b[A\n",
      "Loss: 3.196448:  67%|██████▋   | 80/120 [01:12<00:23,  1.74it/s]\u001b[A\n",
      "Loss: 3.196448:  68%|██████▊   | 81/120 [01:12<00:20,  1.89it/s]\u001b[A\n",
      "Loss: 3.169843:  68%|██████▊   | 81/120 [01:15<00:20,  1.89it/s]\u001b[A\n",
      "Loss: 3.169843:  68%|██████▊   | 82/120 [01:15<00:46,  1.22s/it]\u001b[A\n",
      "Loss: 3.171238:  68%|██████▊   | 82/120 [01:16<00:46,  1.22s/it]\u001b[A\n",
      "Loss: 3.171238:  69%|██████▉   | 83/120 [01:16<00:36,  1.02it/s]\u001b[A\n",
      "Loss: 3.180664:  69%|██████▉   | 83/120 [01:16<00:36,  1.02it/s]\u001b[A\n",
      "Loss: 3.180664:  70%|███████   | 84/120 [01:16<00:28,  1.24it/s]\u001b[A\n",
      "Loss: 3.184922:  70%|███████   | 84/120 [01:16<00:28,  1.24it/s]\u001b[A\n",
      "Loss: 3.184922:  71%|███████   | 85/120 [01:16<00:24,  1.46it/s]\u001b[A\n",
      "Loss: 3.225295:  71%|███████   | 85/120 [01:17<00:24,  1.46it/s]\u001b[A\n",
      "Loss: 3.225295:  72%|███████▏  | 86/120 [01:17<00:20,  1.64it/s]\u001b[A\n",
      "Loss: 3.164485:  72%|███████▏  | 86/120 [01:17<00:20,  1.64it/s]\u001b[A\n",
      "Loss: 3.164485:  72%|███████▎  | 87/120 [01:17<00:18,  1.82it/s]\u001b[A\n",
      "Loss: 3.175674:  72%|███████▎  | 87/120 [01:19<00:18,  1.82it/s]\u001b[A\n",
      "Loss: 3.175674:  73%|███████▎  | 88/120 [01:19<00:31,  1.03it/s]\u001b[A\n",
      "Loss: 3.186464:  73%|███████▎  | 88/120 [01:20<00:31,  1.03it/s]\u001b[A\n",
      "Loss: 3.186464:  74%|███████▍  | 89/120 [01:20<00:24,  1.25it/s]\u001b[A\n",
      "Loss: 3.165785:  74%|███████▍  | 89/120 [01:20<00:24,  1.25it/s]\u001b[A\n",
      "Loss: 3.165785:  75%|███████▌  | 90/120 [01:20<00:20,  1.47it/s]\u001b[A\n",
      "Loss: 3.234635:  75%|███████▌  | 90/120 [01:20<00:20,  1.47it/s]\u001b[A\n",
      "Loss: 3.234635:  76%|███████▌  | 91/120 [01:20<00:17,  1.67it/s]\u001b[A\n",
      "Loss: 3.190277:  76%|███████▌  | 91/120 [01:21<00:17,  1.67it/s]\u001b[A\n",
      "Loss: 3.190277:  77%|███████▋  | 92/120 [01:21<00:15,  1.85it/s]\u001b[A\n",
      "Loss: 3.226779:  77%|███████▋  | 92/120 [01:21<00:15,  1.85it/s]\u001b[A\n",
      "Loss: 3.226779:  78%|███████▊  | 93/120 [01:21<00:14,  1.90it/s]\u001b[A\n",
      "Loss: 3.186115:  78%|███████▊  | 93/120 [01:24<00:14,  1.90it/s]\u001b[A\n",
      "Loss: 3.186115:  78%|███████▊  | 94/120 [01:24<00:31,  1.23s/it]\u001b[A\n",
      "Loss: 3.189997:  78%|███████▊  | 94/120 [01:25<00:31,  1.23s/it]\u001b[A\n",
      "Loss: 3.189997:  79%|███████▉  | 95/120 [01:25<00:24,  1.02it/s]\u001b[A\n",
      "Loss: 3.202566:  79%|███████▉  | 95/120 [01:25<00:24,  1.02it/s]\u001b[A\n",
      "Loss: 3.202566:  80%|████████  | 96/120 [01:25<00:19,  1.24it/s]\u001b[A\n",
      "Loss: 3.186653:  80%|████████  | 96/120 [01:25<00:19,  1.24it/s]\u001b[A\n",
      "Loss: 3.186653:  81%|████████  | 97/120 [01:25<00:15,  1.46it/s]\u001b[A\n",
      "Loss: 3.144266:  81%|████████  | 97/120 [01:26<00:15,  1.46it/s]\u001b[A\n",
      "Loss: 3.144266:  82%|████████▏ | 98/120 [01:26<00:15,  1.45it/s]\u001b[A\n",
      "Loss: 3.168401:  82%|████████▏ | 98/120 [01:27<00:15,  1.45it/s]\u001b[A\n",
      "Loss: 3.168401:  82%|████████▎ | 99/120 [01:27<00:13,  1.51it/s]\u001b[A\n",
      "Loss: 3.196687:  82%|████████▎ | 99/120 [01:29<00:13,  1.51it/s]\u001b[A\n",
      "Loss: 3.196687:  83%|████████▎ | 100/120 [01:29<00:23,  1.17s/it]\u001b[A\n",
      "Loss: 3.275950:  83%|████████▎ | 100/120 [01:29<00:23,  1.17s/it]\u001b[A\n",
      "Loss: 3.275950:  84%|████████▍ | 101/120 [01:29<00:17,  1.06it/s]\u001b[A\n",
      "Loss: 3.189363:  84%|████████▍ | 101/120 [01:30<00:17,  1.06it/s]\u001b[A\n",
      "Loss: 3.189363:  85%|████████▌ | 102/120 [01:30<00:14,  1.27it/s]\u001b[A\n",
      "Loss: 3.217425:  85%|████████▌ | 102/120 [01:30<00:14,  1.27it/s]\u001b[A\n",
      "Loss: 3.217425:  86%|████████▌ | 103/120 [01:30<00:11,  1.48it/s]\u001b[A\n",
      "Loss: 3.220618:  86%|████████▌ | 103/120 [01:31<00:11,  1.48it/s]\u001b[A\n",
      "Loss: 3.220618:  87%|████████▋ | 104/120 [01:31<00:10,  1.56it/s]\u001b[A\n",
      "Loss: 3.152604:  87%|████████▋ | 104/120 [01:32<00:10,  1.56it/s]\u001b[A\n",
      "Loss: 3.152604:  88%|████████▊ | 105/120 [01:32<00:12,  1.24it/s]\u001b[A\n",
      "Loss: 3.251079:  88%|████████▊ | 105/120 [01:34<00:12,  1.24it/s]\u001b[A\n",
      "Loss: 3.251079:  88%|████████▊ | 106/120 [01:34<00:17,  1.28s/it]\u001b[A\n",
      "Loss: 3.157267:  88%|████████▊ | 106/120 [01:35<00:17,  1.28s/it]\u001b[A\n",
      "Loss: 3.157267:  89%|████████▉ | 107/120 [01:35<00:13,  1.02s/it]\u001b[A\n",
      "Loss: 3.159022:  89%|████████▉ | 107/120 [01:35<00:13,  1.02s/it]\u001b[A\n",
      "Loss: 3.159022:  90%|█████████ | 108/120 [01:35<00:10,  1.18it/s]\u001b[A\n",
      "Loss: 3.164780:  90%|█████████ | 108/120 [01:36<00:10,  1.18it/s]\u001b[A\n",
      "Loss: 3.164780:  91%|█████████ | 109/120 [01:36<00:07,  1.40it/s]\u001b[A\n",
      "Loss: 3.164688:  91%|█████████ | 109/120 [01:37<00:07,  1.40it/s]\u001b[A\n",
      "Loss: 3.164688:  92%|█████████▏| 110/120 [01:37<00:08,  1.22it/s]\u001b[A\n",
      "Loss: 3.158613:  92%|█████████▏| 110/120 [01:37<00:08,  1.22it/s]\u001b[A\n",
      "Loss: 3.158613:  92%|█████████▎| 111/120 [01:37<00:06,  1.44it/s]\u001b[A\n",
      "Loss: 3.172624:  92%|█████████▎| 111/120 [01:39<00:06,  1.44it/s]\u001b[A\n",
      "Loss: 3.172624:  93%|█████████▎| 112/120 [01:39<00:08,  1.03s/it]\u001b[A\n",
      "Loss: 3.221013:  93%|█████████▎| 112/120 [01:39<00:08,  1.03s/it]\u001b[A\n",
      "Loss: 3.221013:  94%|█████████▍| 113/120 [01:39<00:05,  1.19it/s]\u001b[A\n",
      "Loss: 3.160035:  94%|█████████▍| 113/120 [01:40<00:05,  1.19it/s]\u001b[A\n",
      "Loss: 3.160035:  95%|█████████▌| 114/120 [01:40<00:04,  1.41it/s]\u001b[A\n",
      "Loss: 3.179746:  95%|█████████▌| 114/120 [01:40<00:04,  1.41it/s]\u001b[A\n",
      "Loss: 3.179746:  96%|█████████▌| 115/120 [01:40<00:03,  1.62it/s]\u001b[A\n",
      "Loss: 3.186763:  96%|█████████▌| 115/120 [01:41<00:03,  1.62it/s]\u001b[A\n",
      "Loss: 3.186763:  97%|█████████▋| 116/120 [01:41<00:02,  1.54it/s]\u001b[A\n",
      "Loss: 3.187425:  97%|█████████▋| 116/120 [01:41<00:02,  1.54it/s]\u001b[A\n",
      "Loss: 3.187425:  98%|█████████▊| 117/120 [01:41<00:01,  1.74it/s]\u001b[A\n",
      "Loss: 3.159214:  98%|█████████▊| 117/120 [01:43<00:01,  1.74it/s]\u001b[A\n",
      "Loss: 3.159214:  98%|█████████▊| 118/120 [01:43<00:01,  1.21it/s]\u001b[A\n",
      "Loss: 3.177966:  98%|█████████▊| 118/120 [01:43<00:01,  1.21it/s]\u001b[A\n",
      "Loss: 3.177966:  99%|█████████▉| 119/120 [01:43<00:00,  1.43it/s]\u001b[A\n",
      "Loss: 3.169845:  99%|█████████▉| 119/120 [01:43<00:00,  1.43it/s]\u001b[A\n",
      "Loss: 3.169845: 100%|██████████| 120/120 [01:43<00:00,  1.64it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [01:44<03:28, 104.13s/it]                   \u001b[A\n",
      "  0%|          | 0/120 [00:00<?, ?it/s]\u001b[A\n",
      "Loss: 3.182863:   0%|          | 0/120 [00:05<?, ?it/s]\u001b[A\n",
      "Loss: 3.182863:   1%|          | 1/120 [00:05<10:51,  5.48s/it]\u001b[A\n",
      "Loss: 3.138405:   1%|          | 1/120 [00:05<10:51,  5.48s/it]\u001b[A\n",
      "Loss: 3.138405:   2%|▏         | 2/120 [00:05<04:54,  2.50s/it]\u001b[A\n",
      "Loss: 3.218824:   2%|▏         | 2/120 [00:06<04:54,  2.50s/it]\u001b[A\n",
      "Loss: 3.218824:   2%|▎         | 3/120 [00:06<03:02,  1.56s/it]\u001b[A\n",
      "Loss: 3.153539:   2%|▎         | 3/120 [00:06<03:02,  1.56s/it]\u001b[A\n",
      "Loss: 3.153539:   3%|▎         | 4/120 [00:06<02:08,  1.11s/it]\u001b[A\n",
      "Loss: 3.297768:   3%|▎         | 4/120 [00:07<02:08,  1.11s/it]\u001b[A\n",
      "Loss: 3.297768:   4%|▍         | 5/120 [00:07<01:37,  1.17it/s]\u001b[A\n",
      "Loss: 3.147419:   4%|▍         | 5/120 [00:07<01:37,  1.17it/s]\u001b[A\n",
      "Loss: 3.147419:   5%|▌         | 6/120 [00:07<01:19,  1.43it/s]\u001b[A\n",
      "Loss: 3.149160:   5%|▌         | 6/120 [00:09<01:19,  1.43it/s]\u001b[A\n",
      "Loss: 3.149160:   6%|▌         | 7/120 [00:09<01:58,  1.05s/it]\u001b[A\n",
      "Loss: 3.153898:   6%|▌         | 7/120 [00:09<01:58,  1.05s/it]\u001b[A\n",
      "Loss: 3.153898:   7%|▋         | 8/120 [00:09<01:44,  1.08it/s]\u001b[A\n",
      "Loss: 3.210685:   7%|▋         | 8/120 [00:10<01:44,  1.08it/s]\u001b[A\n",
      "Loss: 3.210685:   8%|▊         | 9/120 [00:10<01:26,  1.29it/s]\u001b[A\n",
      "Loss: 3.168794:   8%|▊         | 9/120 [00:10<01:26,  1.29it/s]\u001b[A\n",
      "Loss: 3.168794:   8%|▊         | 10/120 [00:10<01:13,  1.50it/s]\u001b[A\n",
      "Loss: 3.190830:   8%|▊         | 10/120 [00:11<01:13,  1.50it/s]\u001b[A\n",
      "Loss: 3.190830:   9%|▉         | 11/120 [00:11<01:03,  1.71it/s]\u001b[A\n",
      "Loss: 3.206554:   9%|▉         | 11/120 [00:11<01:03,  1.71it/s]\u001b[A\n",
      "Loss: 3.206554:  10%|█         | 12/120 [00:11<00:57,  1.88it/s]\u001b[A\n",
      "Loss: 3.160895:  10%|█         | 12/120 [00:13<00:57,  1.88it/s]\u001b[A\n",
      "Loss: 3.160895:  11%|█         | 13/120 [00:13<01:54,  1.07s/it]\u001b[A\n",
      "Loss: 3.208318:  11%|█         | 13/120 [00:14<01:54,  1.07s/it]\u001b[A\n",
      "Loss: 3.208318:  12%|█▏        | 14/120 [00:14<01:32,  1.15it/s]\u001b[A\n",
      "Loss: 3.141417:  12%|█▏        | 14/120 [00:14<01:32,  1.15it/s]\u001b[A\n",
      "Loss: 3.141417:  12%|█▎        | 15/120 [00:14<01:17,  1.35it/s]\u001b[A\n",
      "Loss: 3.186231:  12%|█▎        | 15/120 [00:15<01:17,  1.35it/s]\u001b[A\n",
      "Loss: 3.186231:  13%|█▎        | 16/120 [00:15<01:16,  1.37it/s]\u001b[A\n",
      "Loss: 3.197815:  13%|█▎        | 16/120 [00:15<01:16,  1.37it/s]\u001b[A\n",
      "Loss: 3.197815:  14%|█▍        | 17/120 [00:15<01:05,  1.58it/s]\u001b[A\n",
      "Loss: 3.145514:  14%|█▍        | 17/120 [00:16<01:05,  1.58it/s]\u001b[A\n",
      "Loss: 3.145514:  15%|█▌        | 18/120 [00:16<00:57,  1.77it/s]\u001b[A\n",
      "Loss: 3.184598:  15%|█▌        | 18/120 [00:18<00:57,  1.77it/s]\u001b[A\n",
      "Loss: 3.184598:  16%|█▌        | 19/120 [00:18<01:45,  1.04s/it]\u001b[A\n",
      "Loss: 3.195430:  16%|█▌        | 19/120 [00:18<01:45,  1.04s/it]\u001b[A\n",
      "Loss: 3.195430:  17%|█▋        | 20/120 [00:18<01:25,  1.16it/s]\u001b[A\n",
      "Loss: 3.187066:  17%|█▋        | 20/120 [00:19<01:25,  1.16it/s]\u001b[A\n",
      "Loss: 3.187066:  18%|█▊        | 21/120 [00:19<01:12,  1.36it/s]\u001b[A\n",
      "Loss: 3.146641:  18%|█▊        | 21/120 [00:19<01:12,  1.36it/s]\u001b[A\n",
      "Loss: 3.146641:  18%|█▊        | 22/120 [00:19<01:03,  1.54it/s]\u001b[A\n",
      "Loss: 3.157604:  18%|█▊        | 22/120 [00:20<01:03,  1.54it/s]\u001b[A\n",
      "Loss: 3.157604:  19%|█▉        | 23/120 [00:20<00:56,  1.73it/s]\u001b[A\n",
      "Loss: 3.199336:  19%|█▉        | 23/120 [00:20<00:56,  1.73it/s]\u001b[A\n",
      "Loss: 3.199336:  20%|██        | 24/120 [00:20<00:51,  1.88it/s]\u001b[A\n",
      "Loss: 3.170691:  20%|██        | 24/120 [00:23<00:51,  1.88it/s]\u001b[A\n",
      "Loss: 3.170691:  21%|██        | 25/120 [00:23<01:59,  1.26s/it]\u001b[A\n",
      "Loss: 3.183651:  21%|██        | 25/120 [00:24<01:59,  1.26s/it]\u001b[A\n",
      "Loss: 3.183651:  22%|██▏       | 26/120 [00:24<01:34,  1.00s/it]\u001b[A\n",
      "Loss: 3.150690:  22%|██▏       | 26/120 [00:24<01:34,  1.00s/it]\u001b[A\n",
      "Loss: 3.150690:  22%|██▎       | 27/120 [00:24<01:16,  1.21it/s]\u001b[A\n",
      "Loss: 3.186721:  22%|██▎       | 27/120 [00:25<01:16,  1.21it/s]\u001b[A\n",
      "Loss: 3.186721:  23%|██▎       | 28/120 [00:25<01:20,  1.14it/s]\u001b[A\n",
      "Loss: 3.187531:  23%|██▎       | 28/120 [00:25<01:20,  1.14it/s]\u001b[A\n",
      "Loss: 3.187531:  24%|██▍       | 29/120 [00:25<01:06,  1.36it/s]\u001b[A\n",
      "Loss: 3.194588:  24%|██▍       | 29/120 [00:26<01:06,  1.36it/s]\u001b[A\n",
      "Loss: 3.194588:  25%|██▌       | 30/120 [00:26<00:57,  1.57it/s]\u001b[A\n",
      "Loss: 3.180213:  25%|██▌       | 30/120 [00:28<00:57,  1.57it/s]\u001b[A\n",
      "Loss: 3.180213:  26%|██▌       | 31/120 [00:28<01:28,  1.01it/s]\u001b[A\n",
      "Loss: 3.214793:  26%|██▌       | 31/120 [00:28<01:28,  1.01it/s]\u001b[A\n",
      "Loss: 3.214793:  27%|██▋       | 32/120 [00:28<01:12,  1.22it/s]\u001b[A\n",
      "Loss: 3.143628:  27%|██▋       | 32/120 [00:28<01:12,  1.22it/s]\u001b[A\n",
      "Loss: 3.143628:  28%|██▊       | 33/120 [00:28<01:01,  1.41it/s]\u001b[A\n",
      "Loss: 3.147705:  28%|██▊       | 33/120 [00:29<01:01,  1.41it/s]\u001b[A\n",
      "Loss: 3.147705:  28%|██▊       | 34/120 [00:29<00:53,  1.60it/s]\u001b[A\n",
      "Loss: 3.213850:  28%|██▊       | 34/120 [00:30<00:53,  1.60it/s]\u001b[A\n",
      "Loss: 3.213850:  29%|██▉       | 35/120 [00:30<01:18,  1.08it/s]\u001b[A\n",
      "Loss: 3.167336:  29%|██▉       | 35/120 [00:31<01:18,  1.08it/s]\u001b[A\n",
      "Loss: 3.167336:  30%|███       | 36/120 [00:31<01:05,  1.28it/s]\u001b[A\n",
      "Loss: 3.166379:  30%|███       | 36/120 [00:32<01:05,  1.28it/s]\u001b[A\n",
      "Loss: 3.166379:  31%|███       | 37/120 [00:32<01:22,  1.01it/s]\u001b[A\n",
      "Loss: 3.150608:  31%|███       | 37/120 [00:33<01:22,  1.01it/s]\u001b[A\n",
      "Loss: 3.150608:  32%|███▏      | 38/120 [00:33<01:07,  1.21it/s]\u001b[A\n",
      "Loss: 3.212488:  32%|███▏      | 38/120 [00:33<01:07,  1.21it/s]\u001b[A\n",
      "Loss: 3.212488:  32%|███▎      | 39/120 [00:33<00:56,  1.43it/s]\u001b[A\n",
      "Loss: 3.183634:  32%|███▎      | 39/120 [00:34<00:56,  1.43it/s]\u001b[A\n",
      "Loss: 3.183634:  33%|███▎      | 40/120 [00:34<00:49,  1.63it/s]\u001b[A\n",
      "Loss: 3.146589:  33%|███▎      | 40/120 [00:34<00:49,  1.63it/s]\u001b[A\n",
      "Loss: 3.146589:  34%|███▍      | 41/120 [00:34<00:45,  1.73it/s]\u001b[A\n",
      "Loss: 3.167468:  34%|███▍      | 41/120 [00:35<00:45,  1.73it/s]\u001b[A\n",
      "Loss: 3.167468:  35%|███▌      | 42/120 [00:35<00:41,  1.88it/s]\u001b[A\n",
      "Loss: 3.142457:  35%|███▌      | 42/120 [00:38<00:41,  1.88it/s]\u001b[A\n",
      "Loss: 3.142457:  36%|███▌      | 43/120 [00:38<01:49,  1.42s/it]\u001b[A\n",
      "Loss: 3.228891:  36%|███▌      | 43/120 [00:39<01:49,  1.42s/it]\u001b[A\n",
      "Loss: 3.228891:  37%|███▋      | 44/120 [00:39<01:25,  1.13s/it]\u001b[A\n",
      "Loss: 3.194397:  37%|███▋      | 44/120 [00:39<01:25,  1.13s/it]\u001b[A\n",
      "Loss: 3.194397:  38%|███▊      | 45/120 [00:39<01:08,  1.09it/s]\u001b[A\n",
      "Loss: 3.156101:  38%|███▊      | 45/120 [00:39<01:08,  1.09it/s]\u001b[A\n",
      "Loss: 3.156101:  38%|███▊      | 46/120 [00:39<00:56,  1.30it/s]\u001b[A\n",
      "Loss: 3.226364:  38%|███▊      | 46/120 [00:40<00:56,  1.30it/s]\u001b[A\n",
      "Loss: 3.226364:  39%|███▉      | 47/120 [00:40<00:48,  1.51it/s]\u001b[A\n",
      "Loss: 3.196285:  39%|███▉      | 47/120 [00:40<00:48,  1.51it/s]\u001b[A\n",
      "Loss: 3.196285:  40%|████      | 48/120 [00:40<00:42,  1.68it/s]\u001b[A\n",
      "Loss: 3.241188:  40%|████      | 48/120 [00:41<00:42,  1.68it/s]\u001b[A\n",
      "Loss: 3.241188:  41%|████      | 49/120 [00:41<00:55,  1.27it/s]\u001b[A\n",
      "Loss: 3.138228:  41%|████      | 49/120 [00:42<00:55,  1.27it/s]\u001b[A\n",
      "Loss: 3.138228:  42%|████▏     | 50/120 [00:42<00:47,  1.47it/s]\u001b[A\n",
      "Loss: 3.159882:  42%|████▏     | 50/120 [00:42<00:47,  1.47it/s]\u001b[A\n",
      "Loss: 3.159882:  42%|████▎     | 51/120 [00:42<00:44,  1.55it/s]\u001b[A\n",
      "Loss: 3.183342:  42%|████▎     | 51/120 [00:44<00:44,  1.55it/s]\u001b[A\n",
      "Loss: 3.183342:  43%|████▎     | 52/120 [00:44<00:53,  1.26it/s]\u001b[A\n",
      "Loss: 3.182693:  43%|████▎     | 52/120 [00:44<00:53,  1.26it/s]\u001b[A\n",
      "Loss: 3.182693:  44%|████▍     | 53/120 [00:44<00:45,  1.46it/s]\u001b[A\n",
      "Loss: 3.141409:  44%|████▍     | 53/120 [00:44<00:45,  1.46it/s]\u001b[A\n",
      "Loss: 3.141409:  45%|████▌     | 54/120 [00:44<00:39,  1.66it/s]\u001b[A\n",
      "Loss: 3.198977:  45%|████▌     | 54/120 [00:47<00:39,  1.66it/s]\u001b[A\n",
      "Loss: 3.198977:  46%|████▌     | 55/120 [00:47<01:14,  1.14s/it]\u001b[A\n",
      "Loss: 3.174256:  46%|████▌     | 55/120 [00:47<01:14,  1.14s/it]\u001b[A\n",
      "Loss: 3.174256:  47%|████▋     | 56/120 [00:47<00:58,  1.09it/s]\u001b[A\n",
      "Loss: 3.132957:  47%|████▋     | 56/120 [00:48<00:58,  1.09it/s]\u001b[A\n",
      "Loss: 3.132957:  48%|████▊     | 57/120 [00:48<00:48,  1.30it/s]\u001b[A\n",
      "Loss: 3.130926:  48%|████▊     | 57/120 [00:50<00:48,  1.30it/s]\u001b[A\n",
      "Loss: 3.130926:  48%|████▊     | 58/120 [00:50<01:11,  1.16s/it]\u001b[A\n",
      "Loss: 3.157608:  48%|████▊     | 58/120 [00:50<01:11,  1.16s/it]\u001b[A\n",
      "Loss: 3.157608:  49%|████▉     | 59/120 [00:50<00:56,  1.07it/s]\u001b[A\n",
      "Loss: 3.157373:  49%|████▉     | 59/120 [00:51<00:56,  1.07it/s]\u001b[A\n",
      "Loss: 3.157373:  50%|█████     | 60/120 [00:51<00:46,  1.28it/s]\u001b[A\n",
      "Loss: 3.167873:  50%|█████     | 60/120 [00:52<00:46,  1.28it/s]\u001b[A\n",
      "Loss: 3.167873:  51%|█████     | 61/120 [00:52<00:56,  1.04it/s]\u001b[A\n",
      "Loss: 3.258716:  51%|█████     | 61/120 [00:52<00:56,  1.04it/s]\u001b[A\n",
      "Loss: 3.258716:  52%|█████▏    | 62/120 [00:52<00:46,  1.26it/s]\u001b[A\n",
      "Loss: 3.209009:  52%|█████▏    | 62/120 [00:53<00:46,  1.26it/s]\u001b[A\n",
      "Loss: 3.209009:  52%|█████▎    | 63/120 [00:53<00:38,  1.48it/s]\u001b[A\n",
      "Loss: 3.241929:  52%|█████▎    | 63/120 [00:54<00:38,  1.48it/s]\u001b[A\n",
      "Loss: 3.241929:  53%|█████▎    | 64/120 [00:54<00:51,  1.09it/s]\u001b[A\n",
      "Loss: 3.185972:  53%|█████▎    | 64/120 [00:55<00:51,  1.09it/s]\u001b[A\n",
      "Loss: 3.185972:  54%|█████▍    | 65/120 [00:55<00:42,  1.31it/s]\u001b[A\n",
      "Loss: 3.175754:  54%|█████▍    | 65/120 [00:55<00:42,  1.31it/s]\u001b[A\n",
      "Loss: 3.175754:  55%|█████▌    | 66/120 [00:55<00:35,  1.52it/s]\u001b[A\n",
      "Loss: 3.157857:  55%|█████▌    | 66/120 [00:57<00:35,  1.52it/s]\u001b[A\n",
      "Loss: 3.157857:  56%|█████▌    | 67/120 [00:57<00:48,  1.10it/s]\u001b[A\n",
      "Loss: 3.163590:  56%|█████▌    | 67/120 [00:58<00:48,  1.10it/s]\u001b[A\n",
      "Loss: 3.163590:  57%|█████▋    | 68/120 [00:58<00:59,  1.15s/it]\u001b[A\n",
      "Loss: 3.169202:  57%|█████▋    | 68/120 [00:59<00:59,  1.15s/it]\u001b[A\n",
      "Loss: 3.169202:  57%|█████▊    | 69/120 [00:59<00:47,  1.08it/s]\u001b[A\n",
      "Loss: 3.252519:  57%|█████▊    | 69/120 [00:59<00:47,  1.08it/s]\u001b[A\n",
      "Loss: 3.252519:  58%|█████▊    | 70/120 [00:59<00:38,  1.29it/s]\u001b[A\n",
      "Loss: 3.197380:  58%|█████▊    | 70/120 [00:59<00:38,  1.29it/s]\u001b[A\n",
      "Loss: 3.197380:  59%|█████▉    | 71/120 [00:59<00:32,  1.51it/s]\u001b[A\n",
      "Loss: 3.172272:  59%|█████▉    | 71/120 [01:00<00:32,  1.51it/s]\u001b[A\n",
      "Loss: 3.172272:  60%|██████    | 72/120 [01:00<00:28,  1.70it/s]\u001b[A\n",
      "Loss: 3.189500:  60%|██████    | 72/120 [01:01<00:28,  1.70it/s]\u001b[A\n",
      "Loss: 3.189500:  61%|██████    | 73/120 [01:01<00:34,  1.38it/s]\u001b[A\n",
      "Loss: 3.222876:  61%|██████    | 73/120 [01:04<00:34,  1.38it/s]\u001b[A\n",
      "Loss: 3.222876:  62%|██████▏   | 74/120 [01:04<01:03,  1.39s/it]\u001b[A\n",
      "Loss: 3.160236:  62%|██████▏   | 74/120 [01:04<01:03,  1.39s/it]\u001b[A\n",
      "Loss: 3.160236:  62%|██████▎   | 75/120 [01:04<00:49,  1.09s/it]\u001b[A\n",
      "Loss: 3.178690:  62%|██████▎   | 75/120 [01:05<00:49,  1.09s/it]\u001b[A\n",
      "Loss: 3.178690:  63%|██████▎   | 76/120 [01:05<00:39,  1.13it/s]\u001b[A\n",
      "Loss: 3.159587:  63%|██████▎   | 76/120 [01:05<00:39,  1.13it/s]\u001b[A\n",
      "Loss: 3.159587:  64%|██████▍   | 77/120 [01:05<00:31,  1.34it/s]\u001b[A\n",
      "Loss: 3.260488:  64%|██████▍   | 77/120 [01:06<00:31,  1.34it/s]\u001b[A\n",
      "Loss: 3.260488:  65%|██████▌   | 78/120 [01:06<00:27,  1.54it/s]\u001b[A\n",
      "Loss: 3.164205:  65%|██████▌   | 78/120 [01:06<00:27,  1.54it/s]\u001b[A\n",
      "Loss: 3.164205:  66%|██████▌   | 79/120 [01:06<00:23,  1.71it/s]\u001b[A\n",
      "Loss: 3.151659:  66%|██████▌   | 79/120 [01:09<00:23,  1.71it/s]\u001b[A\n",
      "Loss: 3.151659:  67%|██████▋   | 80/120 [01:09<00:55,  1.39s/it]\u001b[A\n",
      "Loss: 3.180648:  67%|██████▋   | 80/120 [01:10<00:55,  1.39s/it]\u001b[A\n",
      "Loss: 3.180648:  68%|██████▊   | 81/120 [01:10<00:42,  1.10s/it]\u001b[A\n",
      "Loss: 3.160762:  68%|██████▊   | 81/120 [01:10<00:42,  1.10s/it]\u001b[A\n",
      "Loss: 3.160762:  68%|██████▊   | 82/120 [01:10<00:33,  1.12it/s]\u001b[A\n",
      "Loss: 3.151281:  68%|██████▊   | 82/120 [01:10<00:33,  1.12it/s]\u001b[A\n",
      "Loss: 3.151281:  69%|██████▉   | 83/120 [01:10<00:27,  1.34it/s]\u001b[A\n",
      "Loss: 3.201991:  69%|██████▉   | 83/120 [01:11<00:27,  1.34it/s]\u001b[A\n",
      "Loss: 3.201991:  70%|███████   | 84/120 [01:11<00:23,  1.55it/s]\u001b[A\n",
      "Loss: 3.143131:  70%|███████   | 84/120 [01:11<00:23,  1.55it/s]\u001b[A\n",
      "Loss: 3.143131:  71%|███████   | 85/120 [01:11<00:20,  1.72it/s]\u001b[A\n",
      "Loss: 3.166014:  71%|███████   | 85/120 [01:13<00:20,  1.72it/s]\u001b[A\n",
      "Loss: 3.166014:  72%|███████▏  | 86/120 [01:13<00:33,  1.01it/s]\u001b[A\n",
      "Loss: 3.189929:  72%|███████▏  | 86/120 [01:14<00:33,  1.01it/s]\u001b[A\n",
      "Loss: 3.189929:  72%|███████▎  | 87/120 [01:14<00:26,  1.23it/s]\u001b[A\n",
      "Loss: 3.136076:  72%|███████▎  | 87/120 [01:14<00:26,  1.23it/s]\u001b[A\n",
      "Loss: 3.136076:  73%|███████▎  | 88/120 [01:14<00:22,  1.45it/s]\u001b[A\n",
      "Loss: 3.173331:  73%|███████▎  | 88/120 [01:14<00:22,  1.45it/s]\u001b[A\n",
      "Loss: 3.173331:  74%|███████▍  | 89/120 [01:14<00:18,  1.65it/s]\u001b[A\n",
      "Loss: 3.155952:  74%|███████▍  | 89/120 [01:15<00:18,  1.65it/s]\u001b[A\n",
      "Loss: 3.155952:  75%|███████▌  | 90/120 [01:15<00:16,  1.83it/s]\u001b[A\n",
      "Loss: 3.256685:  75%|███████▌  | 90/120 [01:16<00:16,  1.83it/s]\u001b[A\n",
      "Loss: 3.256685:  76%|███████▌  | 91/120 [01:16<00:22,  1.27it/s]\u001b[A\n",
      "Loss: 3.147620:  76%|███████▌  | 91/120 [01:19<00:22,  1.27it/s]\u001b[A\n",
      "Loss: 3.147620:  77%|███████▋  | 92/120 [01:19<00:42,  1.54s/it]\u001b[A\n",
      "Loss: 3.190696:  77%|███████▋  | 92/120 [01:20<00:42,  1.54s/it]\u001b[A\n",
      "Loss: 3.190696:  78%|███████▊  | 93/120 [01:20<00:32,  1.20s/it]\u001b[A\n",
      "Loss: 3.179443:  78%|███████▊  | 93/120 [01:20<00:32,  1.20s/it]\u001b[A\n",
      "Loss: 3.179443:  78%|███████▊  | 94/120 [01:20<00:24,  1.04it/s]\u001b[A\n",
      "Loss: 3.181684:  78%|███████▊  | 94/120 [01:21<00:24,  1.04it/s]\u001b[A\n",
      "Loss: 3.181684:  79%|███████▉  | 95/120 [01:21<00:20,  1.25it/s]\u001b[A\n",
      "Loss: 3.201827:  79%|███████▉  | 95/120 [01:21<00:20,  1.25it/s]\u001b[A\n",
      "Loss: 3.201827:  80%|████████  | 96/120 [01:21<00:16,  1.46it/s]\u001b[A\n",
      "Loss: 3.147859:  80%|████████  | 96/120 [01:22<00:16,  1.46it/s]\u001b[A\n",
      "Loss: 3.147859:  81%|████████  | 97/120 [01:22<00:13,  1.66it/s]\u001b[A\n",
      "Loss: 3.192161:  81%|████████  | 97/120 [01:25<00:13,  1.66it/s]\u001b[A\n",
      "Loss: 3.192161:  82%|████████▏ | 98/120 [01:25<00:29,  1.33s/it]\u001b[A\n",
      "Loss: 3.210102:  82%|████████▏ | 98/120 [01:25<00:29,  1.33s/it]\u001b[A\n",
      "Loss: 3.210102:  82%|████████▎ | 99/120 [01:25<00:22,  1.06s/it]\u001b[A\n",
      "Loss: 3.210436:  82%|████████▎ | 99/120 [01:25<00:22,  1.06s/it]\u001b[A\n",
      "Loss: 3.210436:  83%|████████▎ | 100/120 [01:25<00:17,  1.15it/s]\u001b[A\n",
      "Loss: 3.190042:  83%|████████▎ | 100/120 [01:26<00:17,  1.15it/s]\u001b[A\n",
      "Loss: 3.190042:  84%|████████▍ | 101/120 [01:26<00:13,  1.37it/s]\u001b[A\n",
      "Loss: 3.155280:  84%|████████▍ | 101/120 [01:26<00:13,  1.37it/s]\u001b[A\n",
      "Loss: 3.155280:  85%|████████▌ | 102/120 [01:26<00:11,  1.58it/s]\u001b[A\n",
      "Loss: 3.167131:  85%|████████▌ | 102/120 [01:27<00:11,  1.58it/s]\u001b[A\n",
      "Loss: 3.167131:  86%|████████▌ | 103/120 [01:27<00:09,  1.76it/s]\u001b[A\n",
      "Loss: 3.141134:  86%|████████▌ | 103/120 [01:28<00:09,  1.76it/s]\u001b[A\n",
      "Loss: 3.141134:  87%|████████▋ | 104/120 [01:28<00:13,  1.16it/s]\u001b[A\n",
      "Loss: 3.203792:  87%|████████▋ | 104/120 [01:29<00:13,  1.16it/s]\u001b[A\n",
      "Loss: 3.203792:  88%|████████▊ | 105/120 [01:29<00:10,  1.38it/s]\u001b[A\n",
      "Loss: 3.139399:  88%|████████▊ | 105/120 [01:29<00:10,  1.38it/s]\u001b[A\n",
      "Loss: 3.139399:  88%|████████▊ | 106/120 [01:29<00:08,  1.57it/s]\u001b[A\n",
      "Loss: 3.172300:  88%|████████▊ | 106/120 [01:29<00:08,  1.57it/s]\u001b[A\n",
      "Loss: 3.172300:  89%|████████▉ | 107/120 [01:29<00:07,  1.77it/s]\u001b[A\n",
      "Loss: 3.203491:  89%|████████▉ | 107/120 [01:30<00:07,  1.77it/s]\u001b[A\n",
      "Loss: 3.203491:  90%|█████████ | 108/120 [01:30<00:06,  1.93it/s]\u001b[A\n",
      "Loss: 3.162434:  90%|█████████ | 108/120 [01:31<00:06,  1.93it/s]\u001b[A\n",
      "Loss: 3.162434:  91%|█████████ | 109/120 [01:31<00:07,  1.57it/s]\u001b[A\n",
      "Loss: 3.188347:  91%|█████████ | 109/120 [01:32<00:07,  1.57it/s]\u001b[A\n",
      "Loss: 3.188347:  92%|█████████▏| 110/120 [01:32<00:09,  1.05it/s]\u001b[A\n",
      "Loss: 3.146791:  92%|█████████▏| 110/120 [01:33<00:09,  1.05it/s]\u001b[A\n",
      "Loss: 3.146791:  92%|█████████▎| 111/120 [01:33<00:07,  1.27it/s]\u001b[A\n",
      "Loss: 3.198037:  92%|█████████▎| 111/120 [01:33<00:07,  1.27it/s]\u001b[A\n",
      "Loss: 3.198037:  93%|█████████▎| 112/120 [01:33<00:05,  1.48it/s]\u001b[A\n",
      "Loss: 3.182371:  93%|█████████▎| 112/120 [01:34<00:05,  1.48it/s]\u001b[A\n",
      "Loss: 3.182371:  94%|█████████▍| 113/120 [01:34<00:04,  1.68it/s]\u001b[A\n",
      "Loss: 3.231104:  94%|█████████▍| 113/120 [01:34<00:04,  1.68it/s]\u001b[A\n",
      "Loss: 3.231104:  95%|█████████▌| 114/120 [01:34<00:03,  1.84it/s]\u001b[A\n",
      "Loss: 3.210867:  95%|█████████▌| 114/120 [01:36<00:03,  1.84it/s]\u001b[A\n",
      "Loss: 3.210867:  96%|█████████▌| 115/120 [01:36<00:04,  1.01it/s]\u001b[A\n",
      "Loss: 3.155071:  96%|█████████▌| 115/120 [01:39<00:04,  1.01it/s]\u001b[A\n",
      "Loss: 3.155071:  97%|█████████▋| 116/120 [01:39<00:06,  1.53s/it]\u001b[A\n",
      "Loss: 3.207268:  97%|█████████▋| 116/120 [01:39<00:06,  1.53s/it]\u001b[A\n",
      "Loss: 3.207268:  98%|█████████▊| 117/120 [01:39<00:03,  1.19s/it]\u001b[A\n",
      "Loss: 3.172738:  98%|█████████▊| 117/120 [01:40<00:03,  1.19s/it]\u001b[A\n",
      "Loss: 3.172738:  98%|█████████▊| 118/120 [01:40<00:01,  1.05it/s]\u001b[A\n",
      "Loss: 3.213791:  98%|█████████▊| 118/120 [01:40<00:01,  1.05it/s]\u001b[A\n",
      "Loss: 3.213791:  99%|█████████▉| 119/120 [01:40<00:00,  1.27it/s]\u001b[A\n",
      "Loss: 3.172211:  99%|█████████▉| 119/120 [01:41<00:00,  1.27it/s]\u001b[A\n",
      "Loss: 3.172211: 100%|██████████| 120/120 [01:41<00:00,  1.48it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [03:25<01:42, 102.38s/it]                   \u001b[A\n",
      "  0%|          | 0/120 [00:00<?, ?it/s]\u001b[A\n",
      "Loss: 3.139027:   0%|          | 0/120 [00:05<?, ?it/s]\u001b[A\n",
      "Loss: 3.139027:   1%|          | 1/120 [00:05<10:32,  5.32s/it]\u001b[A\n",
      "Loss: 3.208405:   1%|          | 1/120 [00:06<10:32,  5.32s/it]\u001b[A\n",
      "Loss: 3.208405:   2%|▏         | 2/120 [00:06<06:07,  3.11s/it]\u001b[A\n",
      "Loss: 3.238393:   2%|▏         | 2/120 [00:07<06:07,  3.11s/it]\u001b[A\n",
      "Loss: 3.238393:   2%|▎         | 3/120 [00:07<03:39,  1.88s/it]\u001b[A\n",
      "Loss: 3.166796:   2%|▎         | 3/120 [00:07<03:39,  1.88s/it]\u001b[A\n",
      "Loss: 3.166796:   3%|▎         | 4/120 [00:07<02:30,  1.30s/it]\u001b[A\n",
      "Loss: 3.145596:   3%|▎         | 4/120 [00:08<02:30,  1.30s/it]\u001b[A\n",
      "Loss: 3.145596:   4%|▍         | 5/120 [00:08<01:52,  1.02it/s]\u001b[A\n",
      "Loss: 3.189512:   4%|▍         | 5/120 [00:08<01:52,  1.02it/s]\u001b[A\n",
      "Loss: 3.189512:   5%|▌         | 6/120 [00:08<01:29,  1.28it/s]\u001b[A\n",
      "Loss: 3.168500:   5%|▌         | 6/120 [00:10<01:29,  1.28it/s]\u001b[A\n",
      "Loss: 3.168500:   6%|▌         | 7/120 [00:10<02:19,  1.24s/it]\u001b[A\n",
      "Loss: 3.169939:   6%|▌         | 7/120 [00:11<02:19,  1.24s/it]\u001b[A\n",
      "Loss: 3.169939:   7%|▋         | 8/120 [00:11<01:49,  1.02it/s]\u001b[A\n",
      "Loss: 3.201776:   7%|▋         | 8/120 [00:11<01:49,  1.02it/s]\u001b[A\n",
      "Loss: 3.201776:   8%|▊         | 9/120 [00:11<01:29,  1.25it/s]\u001b[A\n",
      "Loss: 3.198480:   8%|▊         | 9/120 [00:11<01:29,  1.25it/s]\u001b[A\n",
      "Loss: 3.198480:   8%|▊         | 10/120 [00:11<01:15,  1.46it/s]\u001b[A\n",
      "Loss: 3.219316:   8%|▊         | 10/120 [00:12<01:15,  1.46it/s]\u001b[A\n",
      "Loss: 3.219316:   9%|▉         | 11/120 [00:12<01:05,  1.67it/s]\u001b[A\n",
      "Loss: 3.181248:   9%|▉         | 11/120 [00:12<01:05,  1.67it/s]\u001b[A\n",
      "Loss: 3.181248:  10%|█         | 12/120 [00:12<00:59,  1.82it/s]\u001b[A\n",
      "Loss: 3.187354:  10%|█         | 12/120 [00:16<00:59,  1.82it/s]\u001b[A\n",
      "Loss: 3.187354:  11%|█         | 13/120 [00:16<02:35,  1.45s/it]\u001b[A\n",
      "Loss: 3.179949:  11%|█         | 13/120 [00:16<02:35,  1.45s/it]\u001b[A\n",
      "Loss: 3.179949:  12%|█▏        | 14/120 [00:16<02:00,  1.14s/it]\u001b[A\n",
      "Loss: 3.153213:  12%|█▏        | 14/120 [00:17<02:00,  1.14s/it]\u001b[A\n",
      "Loss: 3.153213:  12%|█▎        | 15/120 [00:17<01:36,  1.08it/s]\u001b[A\n",
      "Loss: 3.140981:  12%|█▎        | 15/120 [00:17<01:36,  1.08it/s]\u001b[A\n",
      "Loss: 3.140981:  13%|█▎        | 16/120 [00:17<01:20,  1.29it/s]\u001b[A\n",
      "Loss: 3.149271:  13%|█▎        | 16/120 [00:17<01:20,  1.29it/s]\u001b[A\n",
      "Loss: 3.149271:  14%|█▍        | 17/120 [00:17<01:08,  1.51it/s]\u001b[A\n",
      "Loss: 3.146918:  14%|█▍        | 17/120 [00:18<01:08,  1.51it/s]\u001b[A\n",
      "Loss: 3.146918:  15%|█▌        | 18/120 [00:18<00:59,  1.70it/s]\u001b[A\n",
      "Loss: 3.234701:  15%|█▌        | 18/120 [00:20<00:59,  1.70it/s]\u001b[A\n",
      "Loss: 3.234701:  16%|█▌        | 19/120 [00:20<01:44,  1.04s/it]\u001b[A\n",
      "Loss: 3.148278:  16%|█▌        | 19/120 [00:20<01:44,  1.04s/it]\u001b[A\n",
      "Loss: 3.148278:  17%|█▋        | 20/120 [00:20<01:24,  1.18it/s]\u001b[A\n",
      "Loss: 3.214515:  17%|█▋        | 20/120 [00:21<01:24,  1.18it/s]\u001b[A\n",
      "Loss: 3.214515:  18%|█▊        | 21/120 [00:21<01:10,  1.40it/s]\u001b[A\n",
      "Loss: 3.185906:  18%|█▊        | 21/120 [00:21<01:10,  1.40it/s]\u001b[A\n",
      "Loss: 3.185906:  18%|█▊        | 22/120 [00:21<01:01,  1.60it/s]\u001b[A\n",
      "Loss: 3.206636:  18%|█▊        | 22/120 [00:22<01:01,  1.60it/s]\u001b[A\n",
      "Loss: 3.206636:  19%|█▉        | 23/120 [00:22<00:54,  1.79it/s]\u001b[A\n",
      "Loss: 3.186522:  19%|█▉        | 23/120 [00:22<00:54,  1.79it/s]\u001b[A\n",
      "Loss: 3.186522:  20%|██        | 24/120 [00:22<00:51,  1.88it/s]\u001b[A\n",
      "Loss: 3.152538:  20%|██        | 24/120 [00:24<00:51,  1.88it/s]\u001b[A\n",
      "Loss: 3.152538:  21%|██        | 25/120 [00:24<01:32,  1.03it/s]\u001b[A\n",
      "Loss: 3.206039:  21%|██        | 25/120 [00:24<01:32,  1.03it/s]\u001b[A\n",
      "Loss: 3.206039:  22%|██▏       | 26/120 [00:25<01:15,  1.24it/s]\u001b[A\n",
      "Loss: 3.239135:  22%|██▏       | 26/120 [00:26<01:15,  1.24it/s]\u001b[A\n",
      "Loss: 3.239135:  22%|██▎       | 27/120 [00:26<01:28,  1.05it/s]\u001b[A\n",
      "Loss: 3.171812:  22%|██▎       | 27/120 [00:26<01:28,  1.05it/s]\u001b[A\n",
      "Loss: 3.171812:  23%|██▎       | 28/120 [00:26<01:12,  1.27it/s]\u001b[A\n",
      "Loss: 3.161433:  23%|██▎       | 28/120 [00:27<01:12,  1.27it/s]\u001b[A\n",
      "Loss: 3.161433:  24%|██▍       | 29/120 [00:27<01:01,  1.48it/s]\u001b[A\n",
      "Loss: 3.165309:  24%|██▍       | 29/120 [00:27<01:01,  1.48it/s]\u001b[A\n",
      "Loss: 3.165309:  25%|██▌       | 30/120 [00:27<00:53,  1.68it/s]\u001b[A\n",
      "Loss: 3.143404:  25%|██▌       | 30/120 [00:29<00:53,  1.68it/s]\u001b[A\n",
      "Loss: 3.143404:  26%|██▌       | 31/120 [00:29<01:22,  1.08it/s]\u001b[A\n",
      "Loss: 3.161510:  26%|██▌       | 31/120 [00:29<01:22,  1.08it/s]\u001b[A\n",
      "Loss: 3.161510:  27%|██▋       | 32/120 [00:29<01:08,  1.29it/s]\u001b[A\n",
      "Loss: 3.206068:  27%|██▋       | 32/120 [00:31<01:08,  1.29it/s]\u001b[A\n",
      "Loss: 3.206068:  28%|██▊       | 33/120 [00:31<01:30,  1.04s/it]\u001b[A\n",
      "Loss: 3.175977:  28%|██▊       | 33/120 [00:31<01:30,  1.04s/it]\u001b[A\n",
      "Loss: 3.175977:  28%|██▊       | 34/120 [00:31<01:13,  1.17it/s]\u001b[A\n",
      "Loss: 3.236291:  28%|██▊       | 34/120 [00:32<01:13,  1.17it/s]\u001b[A\n",
      "Loss: 3.236291:  29%|██▉       | 35/120 [00:32<01:01,  1.39it/s]\u001b[A\n",
      "Loss: 3.154092:  29%|██▉       | 35/120 [00:32<01:01,  1.39it/s]\u001b[A\n",
      "Loss: 3.154092:  30%|███       | 36/120 [00:32<00:52,  1.59it/s]\u001b[A\n",
      "Loss: 3.225597:  30%|███       | 36/120 [00:36<00:52,  1.59it/s]\u001b[A\n",
      "Loss: 3.225597:  31%|███       | 37/120 [00:36<02:04,  1.50s/it]\u001b[A\n",
      "Loss: 3.161293:  31%|███       | 37/120 [00:36<02:04,  1.50s/it]\u001b[A\n",
      "Loss: 3.161293:  32%|███▏      | 38/120 [00:36<01:36,  1.17s/it]\u001b[A\n",
      "Loss: 3.172539:  32%|███▏      | 38/120 [00:36<01:36,  1.17s/it]\u001b[A\n",
      "Loss: 3.172539:  32%|███▎      | 39/120 [00:36<01:16,  1.06it/s]\u001b[A\n",
      "Loss: 3.165087:  32%|███▎      | 39/120 [00:37<01:16,  1.06it/s]\u001b[A\n",
      "Loss: 3.165087:  33%|███▎      | 40/120 [00:37<01:02,  1.28it/s]\u001b[A\n",
      "Loss: 3.149099:  33%|███▎      | 40/120 [00:37<01:02,  1.28it/s]\u001b[A\n",
      "Loss: 3.149099:  34%|███▍      | 41/120 [00:37<00:53,  1.48it/s]\u001b[A\n",
      "Loss: 3.167713:  34%|███▍      | 41/120 [00:38<00:53,  1.48it/s]\u001b[A\n",
      "Loss: 3.167713:  35%|███▌      | 42/120 [00:38<00:46,  1.67it/s]\u001b[A\n",
      "Loss: 3.142945:  35%|███▌      | 42/120 [00:41<00:46,  1.67it/s]\u001b[A\n",
      "Loss: 3.142945:  36%|███▌      | 43/120 [00:41<01:53,  1.48s/it]\u001b[A\n",
      "Loss: 3.227724:  36%|███▌      | 43/120 [00:42<01:53,  1.48s/it]\u001b[A\n",
      "Loss: 3.227724:  37%|███▋      | 44/120 [00:42<01:27,  1.16s/it]\u001b[A\n",
      "Loss: 3.136726:  37%|███▋      | 44/120 [00:42<01:27,  1.16s/it]\u001b[A\n",
      "Loss: 3.136726:  38%|███▊      | 45/120 [00:42<01:09,  1.07it/s]\u001b[A\n",
      "Loss: 3.196616:  38%|███▊      | 45/120 [00:42<01:09,  1.07it/s]\u001b[A\n",
      "Loss: 3.196616:  38%|███▊      | 46/120 [00:42<00:57,  1.29it/s]\u001b[A\n",
      "Loss: 3.163269:  38%|███▊      | 46/120 [00:43<00:57,  1.29it/s]\u001b[A\n",
      "Loss: 3.163269:  39%|███▉      | 47/120 [00:43<00:48,  1.49it/s]\u001b[A\n",
      "Loss: 3.153203:  39%|███▉      | 47/120 [00:43<00:48,  1.49it/s]\u001b[A\n",
      "Loss: 3.153203:  40%|████      | 48/120 [00:43<00:42,  1.69it/s]\u001b[A\n",
      "Loss: 3.203208:  40%|████      | 48/120 [00:45<00:42,  1.69it/s]\u001b[A\n",
      "Loss: 3.203208:  41%|████      | 49/120 [00:45<01:15,  1.07s/it]\u001b[A\n",
      "Loss: 3.167605:  41%|████      | 49/120 [00:46<01:15,  1.07s/it]\u001b[A\n",
      "Loss: 3.167605:  42%|████▏     | 50/120 [00:46<01:00,  1.15it/s]\u001b[A\n",
      "Loss: 3.143525:  42%|████▏     | 50/120 [00:47<01:00,  1.15it/s]\u001b[A\n",
      "Loss: 3.143525:  42%|████▎     | 51/120 [00:47<01:08,  1.00it/s]\u001b[A\n",
      "Loss: 3.134002:  42%|████▎     | 51/120 [00:48<01:08,  1.00it/s]\u001b[A\n",
      "Loss: 3.134002:  43%|████▎     | 52/120 [00:48<00:55,  1.22it/s]\u001b[A\n",
      "Loss: 3.213614:  43%|████▎     | 52/120 [00:48<00:55,  1.22it/s]\u001b[A\n",
      "Loss: 3.213614:  44%|████▍     | 53/120 [00:48<00:46,  1.43it/s]\u001b[A\n",
      "Loss: 3.215307:  44%|████▍     | 53/120 [00:48<00:46,  1.43it/s]\u001b[A\n",
      "Loss: 3.215307:  45%|████▌     | 54/120 [00:48<00:41,  1.61it/s]\u001b[A\n",
      "Loss: 3.260851:  45%|████▌     | 54/120 [00:50<00:41,  1.61it/s]\u001b[A\n",
      "Loss: 3.260851:  46%|████▌     | 55/120 [00:50<00:54,  1.20it/s]\u001b[A\n",
      "Loss: 3.149136:  46%|████▌     | 55/120 [00:50<00:54,  1.20it/s]\u001b[A\n",
      "Loss: 3.149136:  47%|████▋     | 56/120 [00:50<00:45,  1.41it/s]\u001b[A\n",
      "Loss: 3.157062:  47%|████▋     | 56/120 [00:51<00:45,  1.41it/s]\u001b[A\n",
      "Loss: 3.157062:  48%|████▊     | 57/120 [00:51<00:49,  1.27it/s]\u001b[A\n",
      "Loss: 3.174291:  48%|████▊     | 57/120 [00:52<00:49,  1.27it/s]\u001b[A\n",
      "Loss: 3.174291:  48%|████▊     | 58/120 [00:52<00:41,  1.48it/s]\u001b[A\n",
      "Loss: 3.195344:  48%|████▊     | 58/120 [00:52<00:41,  1.48it/s]\u001b[A\n",
      "Loss: 3.195344:  49%|████▉     | 59/120 [00:52<00:36,  1.68it/s]\u001b[A\n",
      "Loss: 3.211749:  49%|████▉     | 59/120 [00:52<00:36,  1.68it/s]\u001b[A\n",
      "Loss: 3.211749:  50%|█████     | 60/120 [00:52<00:32,  1.86it/s]\u001b[A\n",
      "Loss: 3.218969:  50%|█████     | 60/120 [00:55<00:32,  1.86it/s]\u001b[A\n",
      "Loss: 3.218969:  51%|█████     | 61/120 [00:55<01:01,  1.05s/it]\u001b[A\n",
      "Loss: 3.154531:  51%|█████     | 61/120 [00:55<01:01,  1.05s/it]\u001b[A\n",
      "Loss: 3.154531:  52%|█████▏    | 62/120 [00:55<00:49,  1.17it/s]\u001b[A\n",
      "Loss: 3.159249:  52%|█████▏    | 62/120 [00:56<00:49,  1.17it/s]\u001b[A\n",
      "Loss: 3.159249:  52%|█████▎    | 63/120 [00:56<00:45,  1.26it/s]\u001b[A\n",
      "Loss: 3.145139:  52%|█████▎    | 63/120 [00:56<00:45,  1.26it/s]\u001b[A\n",
      "Loss: 3.145139:  53%|█████▎    | 64/120 [00:56<00:38,  1.47it/s]\u001b[A\n",
      "Loss: 3.182062:  53%|█████▎    | 64/120 [00:56<00:38,  1.47it/s]\u001b[A\n",
      "Loss: 3.182062:  54%|█████▍    | 65/120 [00:56<00:32,  1.67it/s]\u001b[A\n",
      "Loss: 3.141251:  54%|█████▍    | 65/120 [00:57<00:32,  1.67it/s]\u001b[A\n",
      "Loss: 3.141251:  55%|█████▌    | 66/120 [00:57<00:29,  1.82it/s]\u001b[A\n",
      "Loss: 3.144762:  55%|█████▌    | 66/120 [00:59<00:29,  1.82it/s]\u001b[A\n",
      "Loss: 3.144762:  56%|█████▌    | 67/120 [00:59<00:58,  1.10s/it]\u001b[A\n",
      "Loss: 3.151863:  56%|█████▌    | 67/120 [01:00<00:58,  1.10s/it]\u001b[A\n",
      "Loss: 3.151863:  57%|█████▋    | 68/120 [01:00<00:46,  1.12it/s]\u001b[A\n",
      "Loss: 3.224745:  57%|█████▋    | 68/120 [01:00<00:46,  1.12it/s]\u001b[A\n",
      "Loss: 3.224745:  57%|█████▊    | 69/120 [01:00<00:38,  1.33it/s]\u001b[A\n",
      "Loss: 3.201765:  57%|█████▊    | 69/120 [01:01<00:38,  1.33it/s]\u001b[A\n",
      "Loss: 3.201765:  58%|█████▊    | 70/120 [01:01<00:32,  1.54it/s]\u001b[A\n",
      "Loss: 3.215993:  58%|█████▊    | 70/120 [01:01<00:32,  1.54it/s]\u001b[A\n",
      "Loss: 3.215993:  59%|█████▉    | 71/120 [01:01<00:28,  1.72it/s]\u001b[A\n",
      "Loss: 3.228079:  59%|█████▉    | 71/120 [01:01<00:28,  1.72it/s]\u001b[A\n",
      "Loss: 3.228079:  60%|██████    | 72/120 [01:01<00:25,  1.86it/s]\u001b[A\n",
      "Loss: 3.194492:  60%|██████    | 72/120 [01:03<00:25,  1.86it/s]\u001b[A\n",
      "Loss: 3.194492:  61%|██████    | 73/120 [01:03<00:47,  1.01s/it]\u001b[A\n",
      "Loss: 3.164926:  61%|██████    | 73/120 [01:04<00:47,  1.01s/it]\u001b[A\n",
      "Loss: 3.164926:  62%|██████▏   | 74/120 [01:04<00:38,  1.21it/s]\u001b[A\n",
      "Loss: 3.218709:  62%|██████▏   | 74/120 [01:05<00:38,  1.21it/s]\u001b[A\n",
      "Loss: 3.218709:  62%|██████▎   | 75/120 [01:05<00:40,  1.12it/s]\u001b[A\n",
      "Loss: 3.153957:  62%|██████▎   | 75/120 [01:05<00:40,  1.12it/s]\u001b[A\n",
      "Loss: 3.153957:  63%|██████▎   | 76/120 [01:05<00:33,  1.32it/s]\u001b[A\n",
      "Loss: 3.178407:  63%|██████▎   | 76/120 [01:06<00:33,  1.32it/s]\u001b[A\n",
      "Loss: 3.178407:  64%|██████▍   | 77/120 [01:06<00:28,  1.53it/s]\u001b[A\n",
      "Loss: 3.140231:  64%|██████▍   | 77/120 [01:07<00:28,  1.53it/s]\u001b[A\n",
      "Loss: 3.140231:  65%|██████▌   | 78/120 [01:07<00:37,  1.13it/s]\u001b[A\n",
      "Loss: 3.169555:  65%|██████▌   | 78/120 [01:08<00:37,  1.13it/s]\u001b[A\n",
      "Loss: 3.169555:  66%|██████▌   | 79/120 [01:08<00:33,  1.23it/s]\u001b[A\n",
      "Loss: 3.163229:  66%|██████▌   | 79/120 [01:08<00:33,  1.23it/s]\u001b[A\n",
      "Loss: 3.163229:  67%|██████▋   | 80/120 [01:08<00:27,  1.44it/s]\u001b[A\n",
      "Loss: 3.265239:  67%|██████▋   | 80/120 [01:10<00:27,  1.44it/s]\u001b[A\n",
      "Loss: 3.265239:  68%|██████▊   | 81/120 [01:10<00:33,  1.16it/s]\u001b[A\n",
      "Loss: 3.163966:  68%|██████▊   | 81/120 [01:10<00:33,  1.16it/s]\u001b[A\n",
      "Loss: 3.163966:  68%|██████▊   | 82/120 [01:10<00:27,  1.37it/s]\u001b[A\n",
      "Loss: 3.163037:  68%|██████▊   | 82/120 [01:11<00:27,  1.37it/s]\u001b[A\n",
      "Loss: 3.163037:  69%|██████▉   | 83/120 [01:11<00:33,  1.09it/s]\u001b[A\n",
      "Loss: 3.218745:  69%|██████▉   | 83/120 [01:12<00:33,  1.09it/s]\u001b[A\n",
      "Loss: 3.218745:  70%|███████   | 84/120 [01:12<00:27,  1.31it/s]\u001b[A\n",
      "Loss: 3.180763:  70%|███████   | 84/120 [01:13<00:27,  1.31it/s]\u001b[A\n",
      "Loss: 3.180763:  71%|███████   | 85/120 [01:13<00:30,  1.17it/s]\u001b[A\n",
      "Loss: 3.179619:  71%|███████   | 85/120 [01:13<00:30,  1.17it/s]\u001b[A\n",
      "Loss: 3.179619:  72%|███████▏  | 86/120 [01:13<00:24,  1.38it/s]\u001b[A\n",
      "Loss: 3.187902:  72%|███████▏  | 86/120 [01:14<00:24,  1.38it/s]\u001b[A\n",
      "Loss: 3.187902:  72%|███████▎  | 87/120 [01:14<00:23,  1.42it/s]\u001b[A\n",
      "Loss: 3.193968:  72%|███████▎  | 87/120 [01:14<00:23,  1.42it/s]\u001b[A\n",
      "Loss: 3.193968:  73%|███████▎  | 88/120 [01:14<00:19,  1.61it/s]\u001b[A\n",
      "Loss: 3.284838:  73%|███████▎  | 88/120 [01:18<00:19,  1.61it/s]\u001b[A\n",
      "Loss: 3.284838:  74%|███████▍  | 89/120 [01:18<00:45,  1.46s/it]\u001b[A\n",
      "Loss: 3.185105:  74%|███████▍  | 89/120 [01:18<00:45,  1.46s/it]\u001b[A\n",
      "Loss: 3.185105:  75%|███████▌  | 90/120 [01:18<00:34,  1.14s/it]\u001b[A\n",
      "Loss: 3.160910:  75%|███████▌  | 90/120 [01:18<00:34,  1.14s/it]\u001b[A\n",
      "Loss: 3.160910:  76%|███████▌  | 91/120 [01:18<00:26,  1.09it/s]\u001b[A\n",
      "Loss: 3.146323:  76%|███████▌  | 91/120 [01:19<00:26,  1.09it/s]\u001b[A\n",
      "Loss: 3.146323:  77%|███████▋  | 92/120 [01:19<00:21,  1.30it/s]\u001b[A\n",
      "Loss: 3.153660:  77%|███████▋  | 92/120 [01:19<00:21,  1.30it/s]\u001b[A\n",
      "Loss: 3.153660:  78%|███████▊  | 93/120 [01:19<00:18,  1.45it/s]\u001b[A\n",
      "Loss: 3.159733:  78%|███████▊  | 93/120 [01:20<00:18,  1.45it/s]\u001b[A\n",
      "Loss: 3.159733:  78%|███████▊  | 94/120 [01:20<00:15,  1.65it/s]\u001b[A\n",
      "Loss: 3.201721:  78%|███████▊  | 94/120 [01:23<00:15,  1.65it/s]\u001b[A\n",
      "Loss: 3.201721:  79%|███████▉  | 95/120 [01:23<00:36,  1.47s/it]\u001b[A\n",
      "Loss: 3.141937:  79%|███████▉  | 95/120 [01:24<00:36,  1.47s/it]\u001b[A\n",
      "Loss: 3.141937:  80%|████████  | 96/120 [01:24<00:27,  1.15s/it]\u001b[A\n",
      "Loss: 3.138965:  80%|████████  | 96/120 [01:24<00:27,  1.15s/it]\u001b[A\n",
      "Loss: 3.138965:  81%|████████  | 97/120 [01:24<00:21,  1.08it/s]\u001b[A\n",
      "Loss: 3.138050:  81%|████████  | 97/120 [01:25<00:21,  1.08it/s]\u001b[A\n",
      "Loss: 3.138050:  82%|████████▏ | 98/120 [01:25<00:16,  1.30it/s]\u001b[A\n",
      "Loss: 3.170869:  82%|████████▏ | 98/120 [01:25<00:16,  1.30it/s]\u001b[A\n",
      "Loss: 3.170869:  82%|████████▎ | 99/120 [01:25<00:14,  1.49it/s]\u001b[A\n",
      "Loss: 3.160155:  82%|████████▎ | 99/120 [01:25<00:14,  1.49it/s]\u001b[A\n",
      "Loss: 3.160155:  83%|████████▎ | 100/120 [01:25<00:11,  1.69it/s]\u001b[A\n",
      "Loss: 3.228505:  83%|████████▎ | 100/120 [01:28<00:11,  1.69it/s]\u001b[A\n",
      "Loss: 3.228505:  84%|████████▍ | 101/120 [01:28<00:22,  1.19s/it]\u001b[A\n",
      "Loss: 3.226180:  84%|████████▍ | 101/120 [01:28<00:22,  1.19s/it]\u001b[A\n",
      "Loss: 3.226180:  85%|████████▌ | 102/120 [01:28<00:17,  1.04it/s]\u001b[A\n",
      "Loss: 3.187122:  85%|████████▌ | 102/120 [01:29<00:17,  1.04it/s]\u001b[A\n",
      "Loss: 3.187122:  86%|████████▌ | 103/120 [01:29<00:13,  1.26it/s]\u001b[A\n",
      "Loss: 3.152375:  86%|████████▌ | 103/120 [01:29<00:13,  1.26it/s]\u001b[A\n",
      "Loss: 3.152375:  87%|████████▋ | 104/120 [01:29<00:10,  1.47it/s]\u001b[A\n",
      "Loss: 3.182492:  87%|████████▋ | 104/120 [01:30<00:10,  1.47it/s]\u001b[A\n",
      "Loss: 3.182492:  88%|████████▊ | 105/120 [01:30<00:09,  1.66it/s]\u001b[A\n",
      "Loss: 3.200724:  88%|████████▊ | 105/120 [01:30<00:09,  1.66it/s]\u001b[A\n",
      "Loss: 3.200724:  88%|████████▊ | 106/120 [01:30<00:07,  1.82it/s]\u001b[A\n",
      "Loss: 3.178609:  88%|████████▊ | 106/120 [01:32<00:07,  1.82it/s]\u001b[A\n",
      "Loss: 3.178609:  89%|████████▉ | 107/120 [01:32<00:13,  1.06s/it]\u001b[A\n",
      "Loss: 3.148173:  89%|████████▉ | 107/120 [01:33<00:13,  1.06s/it]\u001b[A\n",
      "Loss: 3.148173:  90%|█████████ | 108/120 [01:33<00:10,  1.15it/s]\u001b[A\n",
      "Loss: 3.217061:  90%|█████████ | 108/120 [01:33<00:10,  1.15it/s]\u001b[A\n",
      "Loss: 3.217061:  91%|█████████ | 109/120 [01:33<00:08,  1.37it/s]\u001b[A\n",
      "Loss: 3.173601:  91%|█████████ | 109/120 [01:34<00:08,  1.37it/s]\u001b[A\n",
      "Loss: 3.173601:  92%|█████████▏| 110/120 [01:34<00:06,  1.58it/s]\u001b[A\n",
      "Loss: 3.165750:  92%|█████████▏| 110/120 [01:35<00:06,  1.58it/s]\u001b[A\n",
      "Loss: 3.165750:  92%|█████████▎| 111/120 [01:35<00:07,  1.23it/s]\u001b[A\n",
      "Loss: 3.161319:  92%|█████████▎| 111/120 [01:35<00:07,  1.23it/s]\u001b[A\n",
      "Loss: 3.161319:  93%|█████████▎| 112/120 [01:35<00:05,  1.45it/s]\u001b[A\n",
      "Loss: 3.198845:  93%|█████████▎| 112/120 [01:37<00:05,  1.45it/s]\u001b[A\n",
      "Loss: 3.198845:  94%|█████████▍| 113/120 [01:37<00:07,  1.04s/it]\u001b[A\n",
      "Loss: 3.166535:  94%|█████████▍| 113/120 [01:37<00:07,  1.04s/it]\u001b[A\n",
      "Loss: 3.166535:  95%|█████████▌| 114/120 [01:37<00:05,  1.18it/s]\u001b[A\n",
      "Loss: 3.192123:  95%|█████████▌| 114/120 [01:38<00:05,  1.18it/s]\u001b[A\n",
      "Loss: 3.192123:  96%|█████████▌| 115/120 [01:38<00:03,  1.40it/s]\u001b[A\n",
      "Loss: 3.169857:  96%|█████████▌| 115/120 [01:38<00:03,  1.40it/s]\u001b[A\n",
      "Loss: 3.169857:  97%|█████████▋| 116/120 [01:38<00:02,  1.60it/s]\u001b[A\n",
      "Loss: 3.163680:  97%|█████████▋| 116/120 [01:40<00:02,  1.60it/s]\u001b[A\n",
      "Loss: 3.163680:  98%|█████████▊| 117/120 [01:40<00:02,  1.12it/s]\u001b[A\n",
      "Loss: 3.157971:  98%|█████████▊| 117/120 [01:40<00:02,  1.12it/s]\u001b[A\n",
      "Loss: 3.157971:  98%|█████████▊| 118/120 [01:40<00:01,  1.34it/s]\u001b[A\n",
      "Loss: 3.179499:  98%|█████████▊| 118/120 [01:41<00:01,  1.34it/s]\u001b[A\n",
      "Loss: 3.179499:  99%|█████████▉| 119/120 [01:41<00:00,  1.23it/s]\u001b[A\n",
      "Loss: 3.152232:  99%|█████████▉| 119/120 [01:42<00:00,  1.23it/s]\u001b[A\n",
      "Loss: 3.152232: 100%|██████████| 120/120 [01:42<00:00,  1.45it/s]\u001b[A\n",
      "100%|██████████| 3/3 [05:07<00:00, 102.49s/it]                   \u001b[A\n",
      "Acc: 0.98: 100%|██████████| 100/100 [00:48<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 835... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>██▇▆▅▄▂▂▂▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁</td></tr><tr><td>mean_iou</td><td>▄▅▃▄▄▃▁▂▄▄▆▃▃▃▄▃▅▂▄▃▃▅▄▅▂▄▄▅▆▃▆█▃▅▆▆▆▄▃█</td></tr><tr><td>mean_pixel_accuracy</td><td>▅█▇███▁▇▅████████▇▇▇████▄████████▇█████▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>3.15223</td></tr><tr><td>mean_iou</td><td>0.24604</td></tr><tr><td>mean_pixel_accuracy</td><td>0.98415</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 3 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">devoted-sweep-2</strong>: <a href=\"https://wandb.ai/adrishd/taco-baseline/runs/hi3mp21p\" target=\"_blank\">https://wandb.ai/adrishd/taco-baseline/runs/hi3mp21p</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211209_234852-hi3mp21p/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bx8xs1tb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: PReLU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbilinear: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0033360005540362257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunet_channels: 8\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adrishd/taco-baseline/runs/bx8xs1tb\" target=\"_blank\">restful-sweep-3</a></strong> to <a href=\"https://wandb.ai/adrishd/taco-baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/adrishd/taco-baseline/sweeps/1dd7a9l1\" target=\"_blank\">https://wandb.ai/adrishd/taco-baseline/sweeps/1dd7a9l1</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/120 [00:00<?, ?it/s]\u001b[A\n",
      "Loss: 4.098440:   0%|          | 0/120 [00:05<?, ?it/s]\u001b[A\n",
      "Loss: 4.098440:   1%|          | 1/120 [00:05<11:52,  5.99s/it]\u001b[A\n",
      "Loss: 4.097165:   1%|          | 1/120 [00:06<11:52,  5.99s/it]\u001b[A\n",
      "Loss: 4.097165:   2%|▏         | 2/120 [00:06<05:03,  2.57s/it]\u001b[A\n",
      "Loss: 4.096506:   2%|▏         | 2/120 [00:06<05:03,  2.57s/it]\u001b[A\n",
      "Loss: 4.096506:   2%|▎         | 3/120 [00:06<02:52,  1.48s/it]\u001b[A\n",
      "Loss: 4.095869:   2%|▎         | 3/120 [00:06<02:52,  1.48s/it]\u001b[A\n",
      "Loss: 4.095869:   3%|▎         | 4/120 [00:06<01:51,  1.04it/s]\u001b[A\n",
      "Loss: 4.094700:   3%|▎         | 4/120 [00:06<01:51,  1.04it/s]\u001b[A\n",
      "Loss: 4.094700:   4%|▍         | 5/120 [00:06<01:18,  1.47it/s]\u001b[A\n",
      "Loss: 4.094517:   4%|▍         | 5/120 [00:06<01:18,  1.47it/s]\u001b[A\n",
      "Loss: 4.094517:   5%|▌         | 6/120 [00:06<00:57,  1.97it/s]\u001b[A\n",
      "Loss: 4.093383:   5%|▌         | 6/120 [00:09<00:57,  1.97it/s]\u001b[A\n",
      "Loss: 4.093383:   6%|▌         | 7/120 [00:09<02:22,  1.26s/it]\u001b[A\n",
      "Loss: 4.092235:   6%|▌         | 7/120 [00:09<02:22,  1.26s/it]\u001b[A\n",
      "Loss: 4.092235:   7%|▋         | 8/120 [00:09<01:42,  1.09it/s]\u001b[A\n",
      "Loss: 4.090256:   7%|▋         | 8/120 [00:10<01:42,  1.09it/s]\u001b[A\n",
      "Loss: 4.090256:   8%|▊         | 9/120 [00:10<01:30,  1.23it/s]\u001b[A\n",
      "Loss: 4.089025:   8%|▊         | 9/120 [00:10<01:30,  1.23it/s]\u001b[A\n",
      "Loss: 4.089025:   8%|▊         | 10/120 [00:10<01:07,  1.63it/s]\u001b[A\n",
      "Loss: 4.089653:   8%|▊         | 10/120 [00:12<01:07,  1.63it/s]\u001b[A\n",
      "Loss: 4.089653:   9%|▉         | 11/120 [00:12<01:55,  1.06s/it]\u001b[A\n",
      "Loss: 4.085392:   9%|▉         | 11/120 [00:12<01:55,  1.06s/it]\u001b[A\n",
      "Loss: 4.085392:  10%|█         | 12/120 [00:12<01:25,  1.26it/s]\u001b[A\n",
      "Loss: 4.085969:  10%|█         | 12/120 [00:13<01:25,  1.26it/s]\u001b[A\n",
      "Loss: 4.085969:  11%|█         | 13/120 [00:13<01:29,  1.20it/s]\u001b[A\n",
      "Loss: 4.081529:  11%|█         | 13/120 [00:13<01:29,  1.20it/s]\u001b[A\n",
      "Loss: 4.081529:  12%|█▏        | 14/120 [00:13<01:07,  1.57it/s]\u001b[A\n",
      "Loss: 4.078930:  12%|█▏        | 14/120 [00:14<01:07,  1.57it/s]\u001b[A\n",
      "Loss: 4.078930:  12%|█▎        | 15/120 [00:14<01:03,  1.66it/s]\u001b[A\n",
      "Loss: 4.080998:  12%|█▎        | 15/120 [00:14<01:03,  1.66it/s]\u001b[A\n",
      "Loss: 4.080998:  13%|█▎        | 16/120 [00:14<00:49,  2.10it/s]\u001b[A\n",
      "Loss: 4.073202:  13%|█▎        | 16/120 [00:16<00:49,  2.10it/s]\u001b[A\n",
      "Loss: 4.073202:  14%|█▍        | 17/120 [00:16<01:34,  1.09it/s]\u001b[A\n",
      "Loss: 4.071997:  14%|█▍        | 17/120 [00:16<01:34,  1.09it/s]\u001b[A\n",
      "Loss: 4.071997:  15%|█▌        | 18/120 [00:16<01:10,  1.44it/s]\u001b[A\n",
      "Loss: 4.068893:  15%|█▌        | 18/120 [00:18<01:10,  1.44it/s]\u001b[A\n",
      "Loss: 4.068893:  16%|█▌        | 19/120 [00:18<01:37,  1.03it/s]\u001b[A\n",
      "Loss: 4.063805:  16%|█▌        | 19/120 [00:18<01:37,  1.03it/s]\u001b[A\n",
      "Loss: 4.063805:  17%|█▋        | 20/120 [00:18<01:13,  1.36it/s]\u001b[A\n",
      "Loss: 4.067950:  17%|█▋        | 20/120 [00:19<01:13,  1.36it/s]\u001b[A\n",
      "Loss: 4.067950:  18%|█▊        | 21/120 [00:19<01:28,  1.11it/s]\u001b[A\n",
      "Loss: 4.059001:  18%|█▊        | 21/120 [00:20<01:28,  1.11it/s]\u001b[A\n",
      "Loss: 4.059001:  18%|█▊        | 22/120 [00:20<01:07,  1.46it/s]\u001b[A\n",
      "Loss: 4.053702:  18%|█▊        | 22/120 [00:22<01:07,  1.46it/s]\u001b[A\n",
      "Loss: 4.053702:  19%|█▉        | 23/120 [00:22<01:44,  1.08s/it]\u001b[A\n",
      "Loss: 4.049546:  19%|█▉        | 23/120 [00:22<01:44,  1.08s/it]\u001b[A\n",
      "Loss: 4.049546:  20%|██        | 24/120 [00:22<01:18,  1.23it/s]\u001b[A\n",
      "Loss: 4.042647:  20%|██        | 24/120 [00:23<01:18,  1.23it/s]\u001b[A\n",
      "Loss: 4.042647:  21%|██        | 25/120 [00:23<01:39,  1.04s/it]\u001b[A\n",
      "Loss: 4.045743:  21%|██        | 25/120 [00:23<01:39,  1.04s/it]\u001b[A\n",
      "Loss: 4.045743:  22%|██▏       | 26/120 [00:24<01:13,  1.28it/s]\u001b[A\n",
      "Loss: 4.038147:  22%|██▏       | 26/120 [00:26<01:13,  1.28it/s]\u001b[A\n",
      "Loss: 4.038147:  22%|██▎       | 27/120 [00:26<01:51,  1.20s/it]\u001b[A\n",
      "Loss: 4.031467:  22%|██▎       | 27/120 [00:26<01:51,  1.20s/it]\u001b[A\n",
      "Loss: 4.031467:  23%|██▎       | 28/120 [00:26<01:22,  1.12it/s]\u001b[A\n",
      "Loss: 4.025524:  23%|██▎       | 28/120 [00:26<01:22,  1.12it/s]\u001b[A\n",
      "Loss: 4.025524:  24%|██▍       | 29/120 [00:26<01:13,  1.24it/s]\u001b[A\n",
      "Loss: 4.021655:  24%|██▍       | 29/120 [00:27<01:13,  1.24it/s]\u001b[A\n",
      "Loss: 4.021655:  25%|██▌       | 30/120 [00:27<00:55,  1.61it/s]\u001b[A\n",
      "Loss: 4.014272:  25%|██▌       | 30/120 [00:28<00:55,  1.61it/s]\u001b[A\n",
      "Loss: 4.014272:  26%|██▌       | 31/120 [00:28<01:06,  1.34it/s]\u001b[A\n",
      "Loss: 4.010547:  26%|██▌       | 31/120 [00:28<01:06,  1.34it/s]\u001b[A\n",
      "Loss: 4.010547:  27%|██▋       | 32/120 [00:28<00:50,  1.73it/s]\u001b[A\n",
      "Loss: 4.001456:  27%|██▋       | 32/120 [00:29<00:50,  1.73it/s]\u001b[A\n",
      "Loss: 4.001456:  28%|██▊       | 33/120 [00:29<01:12,  1.20it/s]\u001b[A\n",
      "Loss: 3.990369:  28%|██▊       | 33/120 [00:29<01:12,  1.20it/s]\u001b[A\n",
      "Loss: 3.990369:  28%|██▊       | 34/120 [00:30<00:55,  1.56it/s]\u001b[A\n",
      "Loss: 3.982575:  28%|██▊       | 34/120 [00:33<00:55,  1.56it/s]\u001b[A\n",
      "Loss: 3.982575:  29%|██▉       | 35/120 [00:33<02:16,  1.60s/it]\u001b[A\n",
      "Loss: 3.975463:  29%|██▉       | 35/120 [00:34<02:16,  1.60s/it]\u001b[A\n",
      "Loss: 3.975463:  30%|███       | 36/120 [00:34<01:38,  1.17s/it]\u001b[A\n",
      "Loss: 3.968982:  30%|███       | 36/120 [00:34<01:38,  1.17s/it]\u001b[A\n",
      "Loss: 3.968982:  31%|███       | 37/120 [00:34<01:12,  1.15it/s]\u001b[A\n",
      "Loss: 3.974224:  31%|███       | 37/120 [00:34<01:12,  1.15it/s]\u001b[A\n",
      "Loss: 3.974224:  32%|███▏      | 38/120 [00:34<00:54,  1.51it/s]\u001b[A\n",
      "Loss: 3.948659:  32%|███▏      | 38/120 [00:34<00:54,  1.51it/s]\u001b[A\n",
      "Loss: 3.948659:  32%|███▎      | 39/120 [00:34<00:42,  1.92it/s]\u001b[A\n",
      "Loss: 3.945990:  32%|███▎      | 39/120 [00:34<00:42,  1.92it/s]\u001b[A\n",
      "Loss: 3.945990:  33%|███▎      | 40/120 [00:34<00:33,  2.36it/s]\u001b[A\n",
      "Loss: 3.930157:  33%|███▎      | 40/120 [00:38<00:33,  2.36it/s]\u001b[A\n",
      "Loss: 3.930157:  34%|███▍      | 41/120 [00:38<01:49,  1.38s/it]\u001b[A\n",
      "Loss: 3.921569:  34%|███▍      | 41/120 [00:38<01:49,  1.38s/it]\u001b[A\n",
      "Loss: 3.921569:  35%|███▌      | 42/120 [00:38<01:19,  1.02s/it]\u001b[A\n",
      "Loss: 3.913390:  35%|███▌      | 42/120 [00:38<01:19,  1.02s/it]\u001b[A\n",
      "Loss: 3.913390:  36%|███▌      | 43/120 [00:38<00:59,  1.30it/s]\u001b[A\n",
      "Loss: 3.902544:  36%|███▌      | 43/120 [00:38<00:59,  1.30it/s]\u001b[A\n",
      "Loss: 3.902544:  37%|███▋      | 44/120 [00:38<00:44,  1.69it/s]\u001b[A\n",
      "Loss: 3.895517:  37%|███▋      | 44/120 [00:39<00:44,  1.69it/s]\u001b[A\n",
      "Loss: 3.895517:  38%|███▊      | 45/120 [00:39<00:36,  2.07it/s]\u001b[A\n",
      "Loss: 3.881879:  38%|███▊      | 45/120 [00:39<00:36,  2.07it/s]\u001b[A\n",
      "Loss: 3.881879:  38%|███▊      | 46/120 [00:39<00:28,  2.57it/s]\u001b[A\n",
      "Loss: 3.869589:  38%|███▊      | 46/120 [00:41<00:28,  2.57it/s]\u001b[A\n",
      "Loss: 3.869589:  39%|███▉      | 47/120 [00:41<01:16,  1.04s/it]\u001b[A\n",
      "Loss: 3.863790:  39%|███▉      | 47/120 [00:42<01:16,  1.04s/it]\u001b[A\n",
      "Loss: 3.863790:  40%|████      | 48/120 [00:42<00:56,  1.28it/s]\u001b[A\n",
      "Loss: 3.858574:  40%|████      | 48/120 [00:42<00:56,  1.28it/s]\u001b[A\n",
      "Loss: 3.858574:  41%|████      | 49/120 [00:42<00:42,  1.67it/s]\u001b[A\n",
      "Loss: 3.867547:  41%|████      | 49/120 [00:42<00:42,  1.67it/s]\u001b[A\n",
      "Loss: 3.867547:  42%|████▏     | 50/120 [00:42<00:33,  2.10it/s]\u001b[A\n",
      "Loss: 3.832052:  42%|████▏     | 50/120 [00:43<00:33,  2.10it/s]\u001b[A\n",
      "Loss: 3.832052:  42%|████▎     | 51/120 [00:43<00:51,  1.33it/s]\u001b[A\n",
      "Loss: 3.825059:  42%|████▎     | 51/120 [00:43<00:51,  1.33it/s]\u001b[A\n",
      "Loss: 3.825059:  43%|████▎     | 52/120 [00:43<00:39,  1.72it/s]\u001b[A\n",
      "Loss: 3.805611:  43%|████▎     | 52/120 [00:46<00:39,  1.72it/s]\u001b[A\n",
      "Loss: 3.805611:  44%|████▍     | 53/120 [00:46<01:12,  1.08s/it]\u001b[A\n",
      "Loss: 3.792439:  44%|████▍     | 53/120 [00:46<01:12,  1.08s/it]\u001b[A\n",
      "Loss: 3.792439:  45%|████▌     | 54/120 [00:46<00:53,  1.24it/s]\u001b[A\n",
      "Loss: 3.792114:  45%|████▌     | 54/120 [00:46<00:53,  1.24it/s]\u001b[A\n",
      "Loss: 3.792114:  46%|████▌     | 55/120 [00:46<00:40,  1.61it/s]\u001b[A\n",
      "Loss: 3.777068:  46%|████▌     | 55/120 [00:46<00:40,  1.61it/s]\u001b[A\n",
      "Loss: 3.777068:  47%|████▋     | 56/120 [00:46<00:31,  2.05it/s]\u001b[A\n",
      "Loss: 3.764446:  47%|████▋     | 56/120 [00:48<00:31,  2.05it/s]\u001b[A\n",
      "Loss: 3.764446:  48%|████▊     | 57/120 [00:48<01:00,  1.03it/s]\u001b[A\n",
      "Loss: 3.744456:  48%|████▊     | 57/120 [00:49<01:00,  1.03it/s]\u001b[A\n",
      "Loss: 3.744456:  48%|████▊     | 58/120 [00:49<00:45,  1.36it/s]\u001b[A\n",
      "Loss: 3.731905:  48%|████▊     | 58/120 [00:50<00:45,  1.36it/s]\u001b[A\n",
      "Loss: 3.731905:  49%|████▉     | 59/120 [00:50<01:00,  1.01it/s]\u001b[A\n",
      "Loss: 3.718335:  49%|████▉     | 59/120 [00:50<01:00,  1.01it/s]\u001b[A\n",
      "Loss: 3.718335:  50%|█████     | 60/120 [00:50<00:44,  1.34it/s]\u001b[A\n",
      "Loss: 3.708524:  50%|█████     | 60/120 [00:50<00:44,  1.34it/s]\u001b[A\n",
      "Loss: 3.708524:  51%|█████     | 61/120 [00:51<00:34,  1.72it/s]\u001b[A\n",
      "Loss: 3.711565:  51%|█████     | 61/120 [00:51<00:34,  1.72it/s]\u001b[A\n",
      "Loss: 3.711565:  52%|█████▏    | 62/120 [00:51<00:26,  2.15it/s]\u001b[A\n",
      "Loss: 3.685617:  52%|█████▏    | 62/120 [00:54<00:26,  2.15it/s]\u001b[A\n",
      "Loss: 3.685617:  52%|█████▎    | 63/120 [00:54<01:21,  1.43s/it]\u001b[A\n",
      "Loss: 3.689822:  52%|█████▎    | 63/120 [00:55<01:21,  1.43s/it]\u001b[A\n",
      "Loss: 3.689822:  53%|█████▎    | 64/120 [00:55<00:58,  1.05s/it]\u001b[A\n",
      "Loss: 3.665059:  53%|█████▎    | 64/120 [00:56<00:58,  1.05s/it]\u001b[A\n",
      "Loss: 3.665059:  54%|█████▍    | 65/120 [00:56<01:02,  1.13s/it]\u001b[A\n",
      "Loss: 3.652154:  54%|█████▍    | 65/120 [00:56<01:02,  1.13s/it]\u001b[A\n",
      "Loss: 3.652154:  55%|█████▌    | 66/120 [00:56<00:45,  1.19it/s]\u001b[A\n",
      "Loss: 3.636524:  55%|█████▌    | 66/120 [00:56<00:45,  1.19it/s]\u001b[A\n",
      "Loss: 3.636524:  56%|█████▌    | 67/120 [00:56<00:34,  1.55it/s]\u001b[A\n",
      "Loss: 3.638032:  56%|█████▌    | 67/120 [00:56<00:34,  1.55it/s]\u001b[A\n",
      "Loss: 3.638032:  57%|█████▋    | 68/120 [00:56<00:26,  1.97it/s]\u001b[A\n",
      "Loss: 3.614526:  57%|█████▋    | 68/120 [01:00<00:26,  1.97it/s]\u001b[A\n",
      "Loss: 3.614526:  57%|█████▊    | 69/120 [01:00<01:17,  1.52s/it]\u001b[A\n",
      "Loss: 3.601886:  57%|█████▊    | 69/120 [01:00<01:17,  1.52s/it]\u001b[A\n",
      "Loss: 3.601886:  58%|█████▊    | 70/120 [01:00<00:56,  1.12s/it]\u001b[A\n",
      "Loss: 3.598951:  58%|█████▊    | 70/120 [01:01<00:56,  1.12s/it]\u001b[A\n",
      "Loss: 3.598951:  59%|█████▉    | 71/120 [01:01<00:41,  1.19it/s]\u001b[A\n",
      "Loss: 3.578586:  59%|█████▉    | 71/120 [01:01<00:41,  1.19it/s]\u001b[A\n",
      "Loss: 3.578586:  60%|██████    | 72/120 [01:01<00:30,  1.55it/s]\u001b[A\n",
      "Loss: 3.586502:  60%|██████    | 72/120 [01:01<00:30,  1.55it/s]\u001b[A\n",
      "Loss: 3.586502:  61%|██████    | 73/120 [01:01<00:23,  2.00it/s]\u001b[A\n",
      "Loss: 3.550585:  61%|██████    | 73/120 [01:01<00:23,  2.00it/s]\u001b[A\n",
      "Loss: 3.550585:  62%|██████▏   | 74/120 [01:01<00:18,  2.49it/s]\u001b[A\n",
      "Loss: 3.546890:  62%|██████▏   | 74/120 [01:04<00:18,  2.49it/s]\u001b[A\n",
      "Loss: 3.546890:  62%|██████▎   | 75/120 [01:04<00:50,  1.12s/it]\u001b[A\n",
      "Loss: 3.544988:  62%|██████▎   | 75/120 [01:04<00:50,  1.12s/it]\u001b[A\n",
      "Loss: 3.544988:  63%|██████▎   | 76/120 [01:04<00:37,  1.19it/s]\u001b[A\n",
      "Loss: 3.521868:  63%|██████▎   | 76/120 [01:04<00:37,  1.19it/s]\u001b[A\n",
      "Loss: 3.521868:  64%|██████▍   | 77/120 [01:04<00:27,  1.54it/s]\u001b[A\n",
      "Loss: 3.512583:  64%|██████▍   | 77/120 [01:05<00:27,  1.54it/s]\u001b[A\n",
      "Loss: 3.512583:  65%|██████▌   | 78/120 [01:05<00:21,  1.95it/s]\u001b[A\n",
      "Loss: 3.514762:  65%|██████▌   | 78/120 [01:05<00:21,  1.95it/s]\u001b[A\n",
      "Loss: 3.514762:  66%|██████▌   | 79/120 [01:05<00:17,  2.41it/s]\u001b[A\n",
      "Loss: 3.506965:  66%|██████▌   | 79/120 [01:05<00:17,  2.41it/s]\u001b[A\n",
      "Loss: 3.506965:  67%|██████▋   | 80/120 [01:05<00:13,  2.87it/s]\u001b[A\n",
      "Loss: 3.490506:  67%|██████▋   | 80/120 [01:08<00:13,  2.87it/s]\u001b[A\n",
      "Loss: 3.490506:  68%|██████▊   | 81/120 [01:08<00:48,  1.24s/it]\u001b[A\n",
      "Loss: 3.493963:  68%|██████▊   | 81/120 [01:09<00:48,  1.24s/it]\u001b[A\n",
      "Loss: 3.493963:  68%|██████▊   | 82/120 [01:09<00:37,  1.00it/s]\u001b[A\n",
      "Loss: 3.466506:  68%|██████▊   | 82/120 [01:09<00:37,  1.00it/s]\u001b[A\n",
      "Loss: 3.466506:  69%|██████▉   | 83/120 [01:09<00:28,  1.32it/s]\u001b[A\n",
      "Loss: 3.484544:  69%|██████▉   | 83/120 [01:09<00:28,  1.32it/s]\u001b[A\n",
      "Loss: 3.484544:  70%|███████   | 84/120 [01:09<00:21,  1.69it/s]\u001b[A\n",
      "Loss: 3.474078:  70%|███████   | 84/120 [01:09<00:21,  1.69it/s]\u001b[A\n",
      "Loss: 3.474078:  71%|███████   | 85/120 [01:09<00:18,  1.89it/s]\u001b[A\n",
      "Loss: 3.473445:  71%|███████   | 85/120 [01:10<00:18,  1.89it/s]\u001b[A\n",
      "Loss: 3.473445:  72%|███████▏  | 86/120 [01:10<00:14,  2.33it/s]\u001b[A\n",
      "Loss: 3.432642:  72%|███████▏  | 86/120 [01:13<00:14,  2.33it/s]\u001b[A\n",
      "Loss: 3.432642:  72%|███████▎  | 87/120 [01:13<00:46,  1.42s/it]\u001b[A\n",
      "Loss: 3.418168:  72%|███████▎  | 87/120 [01:14<00:46,  1.42s/it]\u001b[A\n",
      "Loss: 3.418168:  73%|███████▎  | 88/120 [01:14<00:33,  1.04s/it]\u001b[A\n",
      "Loss: 3.472583:  73%|███████▎  | 88/120 [01:14<00:33,  1.04s/it]\u001b[A\n",
      "Loss: 3.472583:  74%|███████▍  | 89/120 [01:14<00:24,  1.28it/s]\u001b[A\n",
      "Loss: 3.437122:  74%|███████▍  | 89/120 [01:14<00:24,  1.28it/s]\u001b[A\n",
      "Loss: 3.437122:  75%|███████▌  | 90/120 [01:14<00:17,  1.67it/s]\u001b[A\n",
      "Loss: 3.396039:  75%|███████▌  | 90/120 [01:14<00:17,  1.67it/s]\u001b[A\n",
      "Loss: 3.396039:  76%|███████▌  | 91/120 [01:14<00:13,  2.09it/s]\u001b[A\n",
      "Loss: 3.396993:  76%|███████▌  | 91/120 [01:14<00:13,  2.09it/s]\u001b[A\n",
      "Loss: 3.396993:  77%|███████▋  | 92/120 [01:14<00:10,  2.55it/s]\u001b[A\n",
      "Loss: 3.385356:  77%|███████▋  | 92/120 [01:17<00:10,  2.55it/s]\u001b[A\n",
      "Loss: 3.385356:  78%|███████▊  | 93/120 [01:17<00:33,  1.23s/it]\u001b[A\n",
      "Loss: 3.416224:  78%|███████▊  | 93/120 [01:18<00:33,  1.23s/it]\u001b[A\n",
      "Loss: 3.416224:  78%|███████▊  | 94/120 [01:18<00:25,  1.00it/s]\u001b[A\n",
      "Loss: 3.373653:  78%|███████▊  | 94/120 [01:18<00:25,  1.00it/s]\u001b[A\n",
      "Loss: 3.373653:  79%|███████▉  | 95/120 [01:18<00:18,  1.34it/s]\u001b[A\n",
      "Loss: 3.364171:  79%|███████▉  | 95/120 [01:18<00:18,  1.34it/s]\u001b[A\n",
      "Loss: 3.364171:  80%|████████  | 96/120 [01:18<00:13,  1.72it/s]\u001b[A\n",
      "Loss: 3.386304:  80%|████████  | 96/120 [01:18<00:13,  1.72it/s]\u001b[A\n",
      "Loss: 3.386304:  81%|████████  | 97/120 [01:18<00:10,  2.14it/s]\u001b[A\n",
      "Loss: 3.378376:  81%|████████  | 97/120 [01:19<00:10,  2.14it/s]\u001b[A\n",
      "Loss: 3.378376:  82%|████████▏ | 98/120 [01:19<00:08,  2.63it/s]\u001b[A\n",
      "Loss: 3.373587:  82%|████████▏ | 98/120 [01:24<00:08,  2.63it/s]\u001b[A\n",
      "Loss: 3.373587:  82%|████████▎ | 99/120 [01:24<00:40,  1.94s/it]\u001b[A\n",
      "Loss: 3.331197:  82%|████████▎ | 99/120 [01:24<00:40,  1.94s/it]\u001b[A\n",
      "Loss: 3.331197:  83%|████████▎ | 100/120 [01:24<00:28,  1.41s/it]\u001b[A\n",
      "Loss: 3.333831:  83%|████████▎ | 100/120 [01:25<00:28,  1.41s/it]\u001b[A\n",
      "Loss: 3.333831:  84%|████████▍ | 101/120 [01:25<00:19,  1.04s/it]\u001b[A\n",
      "Loss: 3.343742:  84%|████████▍ | 101/120 [01:25<00:19,  1.04s/it]\u001b[A\n",
      "Loss: 3.343742:  85%|████████▌ | 102/120 [01:25<00:14,  1.28it/s]\u001b[A\n",
      "Loss: 3.358538:  85%|████████▌ | 102/120 [01:25<00:14,  1.28it/s]\u001b[A\n",
      "Loss: 3.358538:  86%|████████▌ | 103/120 [01:25<00:10,  1.66it/s]\u001b[A\n",
      "Loss: 3.344803:  86%|████████▌ | 103/120 [01:25<00:10,  1.66it/s]\u001b[A\n",
      "Loss: 3.344803:  87%|████████▋ | 104/120 [01:25<00:07,  2.12it/s]\u001b[A\n",
      "Loss: 3.351134:  87%|████████▋ | 104/120 [01:30<00:07,  2.12it/s]\u001b[A\n",
      "Loss: 3.351134:  88%|████████▊ | 105/120 [01:30<00:25,  1.68s/it]\u001b[A\n",
      "Loss: 3.369947:  88%|████████▊ | 105/120 [01:30<00:25,  1.68s/it]\u001b[A\n",
      "Loss: 3.369947:  88%|████████▊ | 106/120 [01:30<00:17,  1.23s/it]\u001b[A\n",
      "Loss: 3.380472:  88%|████████▊ | 106/120 [01:30<00:17,  1.23s/it]\u001b[A\n",
      "Loss: 3.380472:  89%|████████▉ | 107/120 [01:30<00:11,  1.10it/s]\u001b[A\n",
      "Loss: 3.309839:  89%|████████▉ | 107/120 [01:30<00:11,  1.10it/s]\u001b[A\n",
      "Loss: 3.309839:  90%|█████████ | 108/120 [01:30<00:08,  1.44it/s]\u001b[A\n",
      "Loss: 3.331820:  90%|█████████ | 108/120 [01:30<00:08,  1.44it/s]\u001b[A\n",
      "Loss: 3.331820:  91%|█████████ | 109/120 [01:30<00:05,  1.84it/s]\u001b[A\n",
      "Loss: 3.300046:  91%|█████████ | 109/120 [01:31<00:05,  1.84it/s]\u001b[A\n",
      "Loss: 3.300046:  92%|█████████▏| 110/120 [01:31<00:04,  2.29it/s]\u001b[A\n",
      "Loss: 3.361306:  92%|█████████▏| 110/120 [01:34<00:04,  2.29it/s]\u001b[A\n",
      "Loss: 3.361306:  92%|█████████▎| 111/120 [01:34<00:10,  1.22s/it]\u001b[A\n",
      "Loss: 3.364619:  92%|█████████▎| 111/120 [01:34<00:10,  1.22s/it]\u001b[A\n",
      "Loss: 3.364619:  93%|█████████▎| 112/120 [01:34<00:07,  1.11it/s]\u001b[A\n",
      "Loss: 3.285521:  93%|█████████▎| 112/120 [01:34<00:07,  1.11it/s]\u001b[A\n",
      "Loss: 3.285521:  94%|█████████▍| 113/120 [01:34<00:04,  1.47it/s]\u001b[A\n",
      "Loss: 3.293803:  94%|█████████▍| 113/120 [01:34<00:04,  1.47it/s]\u001b[A\n",
      "Loss: 3.293803:  95%|█████████▌| 114/120 [01:34<00:03,  1.90it/s]\u001b[A\n",
      "Loss: 3.294730:  95%|█████████▌| 114/120 [01:34<00:03,  1.90it/s]\u001b[A\n",
      "Loss: 3.294730:  96%|█████████▌| 115/120 [01:34<00:02,  2.39it/s]\u001b[A\n",
      "Loss: 3.290301:  96%|█████████▌| 115/120 [01:34<00:02,  2.39it/s]\u001b[A\n",
      "Loss: 3.290301:  97%|█████████▋| 116/120 [01:34<00:01,  2.92it/s]\u001b[A\n",
      "Loss: 3.282566:  97%|█████████▋| 116/120 [01:38<00:01,  2.92it/s]\u001b[A\n",
      "Loss: 3.282566:  98%|█████████▊| 117/120 [01:38<00:04,  1.42s/it]\u001b[A\n",
      "Loss: 3.305615:  98%|█████████▊| 117/120 [01:38<00:04,  1.42s/it]\u001b[A\n",
      "Loss: 3.305615:  98%|█████████▊| 118/120 [01:38<00:02,  1.04s/it]\u001b[A\n",
      "Loss: 3.275468:  98%|█████████▊| 118/120 [01:39<00:02,  1.04s/it]\u001b[A\n",
      "Loss: 3.275468:  99%|█████████▉| 119/120 [01:39<00:00,  1.29it/s]\u001b[A\n",
      "Loss: 3.250809:  99%|█████████▉| 119/120 [01:39<00:00,  1.29it/s]\u001b[A\n",
      "Loss: 3.250809: 100%|██████████| 120/120 [01:39<00:00,  1.68it/s]\u001b[A\n",
      " 20%|██        | 1/5 [01:39<06:37, 99.44s/it]                    \u001b[A\n",
      "  0%|          | 0/120 [00:00<?, ?it/s]\u001b[A\n",
      "Loss: 3.288742:   0%|          | 0/120 [00:04<?, ?it/s]\u001b[A\n",
      "Loss: 3.288742:   1%|          | 1/120 [00:04<08:41,  4.39s/it]\u001b[A\n",
      "Loss: 3.298042:   1%|          | 1/120 [00:06<08:41,  4.39s/it]\u001b[A\n",
      "Loss: 3.298042:   2%|▏         | 2/120 [00:06<06:26,  3.28s/it]\u001b[A\n",
      "Loss: 3.242778:   2%|▏         | 2/120 [00:07<06:26,  3.28s/it]\u001b[A\n",
      "Loss: 3.242778:   2%|▎         | 3/120 [00:07<03:37,  1.86s/it]\u001b[A\n",
      "Loss: 3.265469:   2%|▎         | 3/120 [00:07<03:37,  1.86s/it]\u001b[A\n",
      "Loss: 3.265469:   3%|▎         | 4/120 [00:07<02:19,  1.20s/it]\u001b[A\n",
      "Loss: 3.283118:   3%|▎         | 4/120 [00:07<02:19,  1.20s/it]\u001b[A\n",
      "Loss: 3.283118:   4%|▍         | 5/120 [00:07<01:35,  1.20it/s]\u001b[A\n",
      "Loss: 3.245919:   4%|▍         | 5/120 [00:07<01:35,  1.20it/s]\u001b[A\n",
      "Loss: 3.245919:   5%|▌         | 6/120 [00:07<01:09,  1.63it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "count = 5 # Run 5 sweeps\n",
    "wandb.agent(\n",
    "    sweep_id,\n",
    "    function=train,\n",
    "    count=count\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

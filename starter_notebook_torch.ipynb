{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998e780",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6d35d3b1",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -Uq wandb tqdm torchsummary\n",
    "!pip install -Uq randomname # for generating funky names for the sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09226c8c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f370a195",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# Define wandb username, project name and dataset path\n",
    "wandb_username = \"adrishd\"\n",
    "wandb_project = \"taco-baseline\"\n",
    "dataset_artifact = \"adrishd/taco/taco:pytorch\"\n",
    "\n",
    "# Downloading dataset\n",
    "# use root parameter in artifacts.download(root=<custom_path>)\n",
    "# to specify download directory. else download in the current directory.\n",
    "api = wandb.Api()\n",
    "artifact = api.artifact(dataset_artifact)\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d95cc",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "3ee16cc8",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "import randomname\n",
    "import tacoloader\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import torchsummary\n",
    "import time\n",
    "import tqdm as tqdm\n",
    "import torchvision\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e501f702",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "bfd01861",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "# Constants in the training pipeline\n",
    "train_batch_size = 10\n",
    "test_batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac74ccd",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d5c5830e",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "h, w, c = 512, 512, 3  # height, width and channel of images\n",
    "# Use torchvision.transpose.Compose to compose multiple transformations\n",
    "# together. Refer to: https://pytorch.org/vision/stable/transforms.html\n",
    "transform = torchvision.transforms.Resize(\n",
    "    (h, w), torchvision.transforms.InterpolationMode.NEAREST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911aa78",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a4f53f9c",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "# By default an LRU cache is used for storing the last recently loaded image\n",
    "# and re-using that in the next epoch.\n",
    "# To store `all` the loaded images in memory and reuse them in the next epochs\n",
    "# set cache_fn=taco_loader.cache_fn in tacoloader.load_dataset(...)\n",
    "# an user can also increase the size of LRU cache, by\n",
    "# setting cache_fn=functools.lru_cache(maxsize=<int size>) in\n",
    "# tacoloader.load_dataset(...)\n",
    "\n",
    "dataset, collate_fn = tacoloader.load_dataset(\n",
    "    artifact_dir, tacoloader.Environment.TORCH, transform_fn=transform\n",
    ")\n",
    "\n",
    "# Splitting Dataset to 80%-20% for training and testing, respectively\n",
    "train_split = 0.8\n",
    "dataset_size = len(dataset)\n",
    "indices = range(dataset_size)\n",
    "train_indices = indices[: int(train_split * dataset_size)]\n",
    "test_indices = indices[int(train_split * dataset_size) + 1 :]\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee1508c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "006b3bad",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "# Creating Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    collate_fn=dataset.collate_fn,\n",
    "    num_workers=6,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    collate_fn=dataset.collate_fn,\n",
    "    num_workers=6,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ce657",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "60e179ac",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "def viz_mask(image, pred_mask, true_mask):\n",
    "    # Visualize segmentation mask on W&B dashboard\n",
    "    # image: torch tensor of dim [c, h, w]\n",
    "    # pred_mask: detached torch tensor of dim [h, w]\n",
    "    # true_mask: torch tensor of dim [h, w]\n",
    "    pred_labels = torch.unique(pred_mask).cpu().numpy().tolist()\n",
    "    predicted_class_labels = {\n",
    "        i: x for i, x in enumerate(dataset.get_categories(pred_labels))\n",
    "    }\n",
    "    gt_labels = torch.unique(true_mask).cpu().numpy().tolist()\n",
    "    ground_truth_labels = {\n",
    "        i: x for i, x in enumerate(dataset.get_categories(gt_labels))\n",
    "    }\n",
    "    wandb_image = wandb.Image(\n",
    "        image.cpu(),\n",
    "        masks={\n",
    "            \"prediction\": {\n",
    "                \"mask_data\": pred_mask.squeeze().cpu().numpy(),\n",
    "                \"class_labels\": predicted_class_labels,\n",
    "            },\n",
    "            \"ground_truth\": {\n",
    "                \"mask_data\": true_mask.cpu().numpy(),\n",
    "                \"class_labels\": ground_truth_labels,\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "    wandb.log({\"semantic_segmentation\": wandb_image})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b71349",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b883a676",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "source": [
    "## Model Design and Implementations\n",
    "### Starter Code: Helper Modules for UNet Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ab9103",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "dce441a7",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function for getting activation functions\n",
    "# from torch.nn given the function name.\n",
    "# activations with inplace operations, are enabled\n",
    "# by default.\n",
    "import inspect\n",
    "import functools\n",
    "\n",
    "\n",
    "def get_activation_fn(fn_name):\n",
    "    fn = getattr(torch.nn, fn_name)\n",
    "    isinplace = \"inplace\" in inspect.signature(fn).parameters\n",
    "    if isinplace:\n",
    "        fn = functools.partial(fn, inplace=True)\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1238dc17",
   "metadata": {
    "gradient": {
     "editing": true,
     "id": "d265aed6",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "# Dummy baseline UNet model based on:\n",
    "# https://github.com/xiaopeng-liao/Pytorch-UNet/blob/master/unet/unet_parts.py\n",
    "class double_conv(torch.nn.Module):\n",
    "    \"\"\"(conv => BN => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_ch, out_ch, activation_fn_name):\n",
    "        super(double_conv, self).__init__()\n",
    "        activation_fn = get_activation_fn(activation_fn_name)\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            torch.nn.BatchNorm2d(out_ch),\n",
    "            activation_fn(),\n",
    "            torch.nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            torch.nn.BatchNorm2d(out_ch),\n",
    "            activation_fn(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class inconv(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation_fn):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch, activation_fn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class down(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation_fn):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(2), double_conv(in_ch, out_ch, activation_fn)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class up(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation_fn, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "        if bilinear:\n",
    "            self.up = torch.nn.Upsample(\n",
    "                scale_factor=2, mode=\"bilinear\", align_corners=True\n",
    "            )\n",
    "        else:\n",
    "            self.up = torch.nn.ConvTranspose2d(in_ch // 2, in_ch // 2, 2, stride=2)\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch, activation_fn)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffX = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2))\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class outconv(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_ch, out_ch, 1)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031168ab",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "23fef13c",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, config):\n",
    "        super(UNet, self).__init__()\n",
    "        mid_channels = config[\"unet_channels\"]\n",
    "        activation_fn = config[\"activation_fn\"]\n",
    "        self.inc = inconv(n_channels, mid_channels, activation_fn)\n",
    "        self.down1 = down(mid_channels, mid_channels * 2, activation_fn)\n",
    "        self.down2 = down(mid_channels * 2, mid_channels * 4, activation_fn)\n",
    "        self.down3 = down(mid_channels * 4, mid_channels * 8, activation_fn)\n",
    "        self.down4 = down(mid_channels * 8, mid_channels * 8, activation_fn)\n",
    "        self.up1 = up(\n",
    "            mid_channels * 16,\n",
    "            mid_channels * 4,\n",
    "            activation_fn,\n",
    "            bilinear=config[\"bilinear\"],\n",
    "        )\n",
    "        self.up2 = up(\n",
    "            mid_channels * 8,\n",
    "            mid_channels * 2,\n",
    "            activation_fn,\n",
    "            bilinear=config[\"bilinear\"],\n",
    "        )\n",
    "        self.up3 = up(\n",
    "            mid_channels * 4, mid_channels, activation_fn, bilinear=config[\"bilinear\"]\n",
    "        )\n",
    "        self.up4 = up(\n",
    "            mid_channels * 2, mid_channels, activation_fn, bilinear=config[\"bilinear\"]\n",
    "        )\n",
    "        self.outc = outconv(mid_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd6c46",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7e10b348",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5729b33c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c9e53f28",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "source": [
    "### Training, Logging, Finding Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6dbf4",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "bcb49042",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy metrics and utility functions\n",
    "\n",
    "\n",
    "def pixel_accuracy(pred, ground):\n",
    "    eqmap = torch.eq(pred, ground).int()\n",
    "    return eqmap.sum().float() / eqmap.numel()\n",
    "\n",
    "\n",
    "# mIOU based on: https://stackoverflow.com/questions/62461379/multiclass-semantic-segmentation-model-evaluation\n",
    "def mIOU(pred, label, num_classes):\n",
    "    iou_list = list()\n",
    "    present_iou_list = list()\n",
    "    pred = pred.view(-1)\n",
    "    label = label.view(-1)\n",
    "    for sem_class in range(num_classes):\n",
    "        pred_inds = pred == sem_class\n",
    "        target_inds = label == sem_class\n",
    "        if target_inds.long().sum() == 0:\n",
    "            iou_now = torch.nan\n",
    "        else:\n",
    "            intersection_now = (pred_inds[target_inds]).long().sum()\n",
    "            union_now = (\n",
    "                pred_inds.long().sum() + target_inds.long().sum() - intersection_now\n",
    "            )\n",
    "            iou_now = intersection_now.float() / union_now.float()\n",
    "            present_iou_list.append(iou_now)\n",
    "        iou_list.append(iou_now)\n",
    "    return torch.mean(torch.stack(present_iou_list))\n",
    "\n",
    "\n",
    "def save_model(model, run):\n",
    "    fname = \"trained_model.%s.pt\" % run.id\n",
    "    torch.save(model, fname)\n",
    "    metadata = dict(framework=\"pytorch\")\n",
    "    artifact = wandb.Artifact(\"trained_model\", type=\"model\", metadata=metadata)\n",
    "    artifact.add_file(fname)\n",
    "    run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3537fb2",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "14b4359a",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    with wandb.init(entity=wandb_username, project=wandb_project) as run:\n",
    "        config = wandb.config\n",
    "        num_classes = dataset.len_categories\n",
    "        unet = UNet(3, num_classes, config).to(device)\n",
    "        optim = torch.optim.Adam(unet.parameters(), lr=config[\"lr\"])\n",
    "        for x in tqdm.tqdm(range(config[\"epochs\"])):\n",
    "            bar = tqdm.tqdm(train_loader)\n",
    "            for data in bar:\n",
    "                optim.zero_grad()\n",
    "                segmask = unet(data.images.to(device))\n",
    "                loss = loss_fn(segmask, data.masks.to(device).long())\n",
    "                loss.backward()\n",
    "                bar.set_description(\"Loss: %f\" % loss.detach().cpu())\n",
    "                wandb.log({\"loss\": loss.detach().cpu()})\n",
    "                optim.step()\n",
    "        save_model(unet, run)\n",
    "        test_bar = tqdm.tqdm(test_loader, position=0)\n",
    "        with torch.no_grad():\n",
    "            for data in test_bar:\n",
    "                segmask = unet(data.images.to(device))\n",
    "                mask = torch.argmax(segmask, dim=1).detach().cpu()\n",
    "                acc = pixel_accuracy(mask, data.masks)\n",
    "                miou = mIOU(mask, data.masks, num_classes).numpy()\n",
    "                test_bar.set_description(\"Acc: %.2f\" % acc)\n",
    "                wandb.log({\"mean_pixel_accuracy\": acc, \"mean_iou\": miou})\n",
    "        # Draw one sample and visualize the mask for each sweep\n",
    "        sample = test_dataset[0]\n",
    "        segmask = unet(sample.image.unsqueeze(0).to(device))\n",
    "        mask = torch.argmax(segmask, dim=1).detach().squeeze()\n",
    "        viz_mask(sample.image, mask, sample.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66f518",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "19893452",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "# Using wandb's hyperparameter optimization framework sweeps\n",
    "# More information can be found here: https://docs.wandb.ai/guides/sweeps\n",
    "sweep_name = randomname.get_name()\n",
    "sweep_config = {\n",
    "    \"name\": sweep_name,\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"mean_iou\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"epochs\": {\"values\": [0]},\n",
    "        \"lr\": {\"min\": 1e-4, \"max\": 1e-2},\n",
    "        \"activation_fn\": {\"values\": [\"ReLU\", \"LeakyReLU\", \"PReLU\"]},\n",
    "        \"unet_channels\": {\"values\": [8, 16, 32]},\n",
    "        \"bilinear\": {\"values\": [True, False]},\n",
    "    },\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, entity=wandb_username, project=wandb_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d3f4df",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "81359db5",
     "kernelId": "20d3a74c-2e60-44e1-8d8e-8b0e549b64c2"
    }
   },
   "outputs": [],
   "source": [
    "count = 5  # Run 5 sweeps\n",
    "wandb.agent(sweep_id, function=train, count=count)\n",
    "sweep = wandb.Api().sweep(\"/\".join([wandb_username, wandb_project, sweep_id]))\n",
    "print(\"Best Run: %s\" % sweep.best_run().url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

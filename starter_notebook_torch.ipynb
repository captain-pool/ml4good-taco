{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497dae0",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "410acd86",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install -Uq wandb tqdm torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dede3fff",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f792ea34",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwandb_fc\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/opt/conda/lib/python3.8/site-packages/IPython/html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adrishd/taco-baseline/runs/q2munsi5\" target=\"_blank\">hardy-butterfly-42</a></strong> to <a href=\"https://wandb.ai/adrishd/taco-baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact taco:pytorch, 2507.15MB. 1503 files... Done. 0:0:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3052... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">hardy-butterfly-42</strong>: <a href=\"https://wandb.ai/adrishd/taco-baseline/runs/q2munsi5\" target=\"_blank\">https://wandb.ai/adrishd/taco-baseline/runs/q2munsi5</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211207_203115-q2munsi5/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "# Define wandb username, project name and dataset path\n",
    "wandb_username = \"adrishd\"\n",
    "wandb_project = \"taco-baseline\"\n",
    "dataset_artifact = 'adrishd/taco/taco:pytorch'\n",
    "\n",
    "# Downloading dataset\n",
    "# use root parameter in artifacts.download(root=<custom_path>)\n",
    "# to specify download directory. else download in the current directory.\n",
    "with wandb.init(entity=wandb_username, project=wandb_project) as run:\n",
    "    artifact = run.use_artifact(dataset_artifact, type='dataset')\n",
    "    artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b5bcc1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "e91eab1b",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "import tacoloader\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import torchsummary\n",
    "import time\n",
    "import tqdm\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d392c9c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7d2bd474",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "h, w, c = 512, 512, 3 # height, width and channel of images\n",
    "# Use torchvision.transpose.Compose to compose multiple transformations\n",
    "# together. Refer to: https://pytorch.org/vision/stable/transforms.html\n",
    "transform = torchvision.transforms.Resize(\n",
    "        (h, w),\n",
    "        torchvision.transforms.InterpolationMode.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b54948ef",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f6158a0b",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "# Constants in the training pipeline\n",
    "train_batch_size = 10\n",
    "test_batch_size = 1\n",
    "split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97437ffe",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "41dd26e6",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE! Installing ujson may make loading annotations faster.\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset, collate_fn = tacoloader.load_dataset(artifact_dir, tacoloader.Environment.TORCH, transform_fn=transform)\n",
    "# Splitting Dataset to 80%-20% for training and testing\n",
    "dataset_size = len(dataset)\n",
    "indices = range(dataset_size)\n",
    "train_indices = indices[:int(split * dataset_size)]\n",
    "test_indices = indices[int(split * dataset_size) + 1:]\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b11d744d",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6b21465a",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    collate_fn=dataset.collate_fn,\n",
    "    num_workers=6,\n",
    "    shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    collate_fn=dataset.collate_fn,\n",
    "    num_workers=6,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c52eae5",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d48432ce",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "def viz_mask(image, pred_mask, true_mask):\n",
    "    # Visualize segmentation mask on W&B dashboard\n",
    "    # image: torch tensor of dim [c, h, w]\n",
    "    # pred_mask: detached torch tensor of dim [h, w]\n",
    "    # true_mask: torch tensor of dim [h, w]\n",
    "    pred_labels = torch.unique(pred_mask).cpu().numpy().tolist()\n",
    "    predicted_class_labels = {\n",
    "        i : x for i, x in enumerate(dataset.get_categories(pred_labels))\n",
    "    }\n",
    "    gt_labels = torch.unique(true_mask).cpu().numpy().tolist()\n",
    "    ground_truth_labels = {\n",
    "        i: x for i, x in enumerate(dataset.get_categories(gt_labels))\n",
    "    }\n",
    "    wandb_image = wandb.Image(image.cpu(), masks={\n",
    "        \"prediction\": {\n",
    "            \"mask_data\": pred_mask.squeeze().cpu().numpy(),\n",
    "            \"class_labels\": predicted_class_labels\n",
    "        },\n",
    "        \"ground_truth\": {\n",
    "            \"mask_data\": true_mask.cpu().numpy(),\n",
    "            \"class_labels\": ground_truth_labels\n",
    "        }\n",
    "    })\n",
    "    wandb.log({\"semantic_segmentation\" : wandb_image})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ef2a3",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "4136b2f6",
     "kernelId": ""
    }
   },
   "source": [
    "## Model Design and Implementations\n",
    "### Starter Code: Helper Modules for UNet Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c7088c7",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d85d6f93",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "# Helper function for getting activation functions\n",
    "# from torch.nn given the function name.\n",
    "# activations with inplace operations, are enabled\n",
    "# by default.\n",
    "import inspect\n",
    "import functools\n",
    "def get_activation_fn(fn_name):\n",
    "    fn = getattr(torch.nn, fn_name)\n",
    "    isinplace = \"inplace\" in inspect.signature(fn).parameters\n",
    "    if isinplace:\n",
    "        fn = functools.partial(fn, inplace=True)\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0750b10c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "18e01a6c",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dummy baseline UNet model based on:\n",
    "# https://github.com/xiaopeng-liao/Pytorch-UNet/blob/master/unet/unet_parts.py\n",
    "class double_conv(torch.nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch, activation_fn_name):\n",
    "        super(double_conv, self).__init__()\n",
    "        activation_fn = get_activation_fn(activation_fn_name)\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            torch.nn.BatchNorm2d(out_ch),\n",
    "            activation_fn(),\n",
    "            torch.nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            torch.nn.BatchNorm2d(out_ch),\n",
    "            activation_fn()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class inconv(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation_fn):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch, activation_fn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class down(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation_fn):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            double_conv(in_ch, out_ch, activation_fn)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class up(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation_fn, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "        if bilinear:\n",
    "            self.up = torch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = torch.nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch, activation_fn)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffX = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
    "                        diffY // 2, diffY - diffY//2))\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class outconv(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_ch, out_ch, 1)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d90d766d",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "0a18a23e",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, config):\n",
    "        super(UNet, self).__init__()\n",
    "        mid_channels = config[\"unet_channels\"]\n",
    "        activation_fn = config[\"activation_fn\"]\n",
    "        self.inc = inconv(n_channels,\n",
    "                          mid_channels,\n",
    "                          activation_fn)\n",
    "        self.down1 = down(mid_channels,\n",
    "                          mid_channels * 2,\n",
    "                          activation_fn)\n",
    "        self.down2 = down(mid_channels * 2,\n",
    "                          mid_channels * 4,\n",
    "                          activation_fn)\n",
    "        self.down3 = down(mid_channels * 4,\n",
    "                          mid_channels * 8,\n",
    "                          activation_fn)\n",
    "        self.down4 = down(mid_channels * 8,\n",
    "                          mid_channels * 8,\n",
    "                          activation_fn)\n",
    "        self.up1 = up(mid_channels * 16,\n",
    "                      mid_channels * 4,\n",
    "                      activation_fn,\n",
    "                      bilinear=config[\"bilinear\"])\n",
    "        self.up2 = up(mid_channels * 8,\n",
    "                      mid_channels * 2,\n",
    "                      activation_fn,\n",
    "                      bilinear=config[\"bilinear\"])\n",
    "        self.up3 = up(mid_channels * 4,\n",
    "                      mid_channels,\n",
    "                      activation_fn,\n",
    "                      bilinear=config[\"bilinear\"])\n",
    "        self.up4 = up(mid_channels * 2,\n",
    "                      mid_channels,\n",
    "                      activation_fn,\n",
    "                      bilinear=config[\"bilinear\"])\n",
    "        self.outc = outconv(mid_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b22b0a",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "4d696afd",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c5df08",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "78789bf5",
     "kernelId": ""
    }
   },
   "source": [
    "### Training, Logging, Finding Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46fdbdbc",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "845b4e17",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: cmd01r6y\n",
      "Sweep URL: https://wandb.ai/adrishd/taco-baseline/sweeps/cmd01r6y\n"
     ]
    }
   ],
   "source": [
    "# Using wandb's hyperparameter optimization framework sweeps\n",
    "# More information can be found here: https://docs.wandb.ai/guides/sweeps\n",
    "sweep_config = {\n",
    "    \"name\" : \"sweep-params\",\n",
    "    \"method\" : \"bayes\",\n",
    "    \"metric\" : {\n",
    "        \"name\": \"pixacc\",\n",
    "        \"goal\": \"minimize\"\n",
    "    },\n",
    "    \"parameters\" : {\n",
    "        \"epochs\" : {\n",
    "            \"values\": [1, 3, 5]\n",
    "        },\n",
    "        \"lr\" : {\n",
    "            \"min\": 1e-4,\n",
    "            \"max\": 1e-2\n",
    "        },\n",
    "        \"activation_fn\" : {\n",
    "            \"values\" : [\"ReLU\", \"LeakyReLU\", \"PReLU\"]\n",
    "        },\n",
    "        \"unet_channels\" : {\n",
    "            \"values\" : [8, 16, 32]\n",
    "        },\n",
    "        \"bilinear\" : {\n",
    "            \"values\" : [True, False]\n",
    "        },\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(\n",
    "    sweep_config,\n",
    "    entity=wandb_username,\n",
    "    project=wandb_project\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2d7210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_accuracy(pred, ground):\n",
    "    eqmap = torch.eq(pred.cpu(), ground).int()\n",
    "    return float(eqmap.sum()) / eqmap.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83eb9bc5",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d0ee0bed",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    with wandb.init(entity=wandb_username, project=wandb_project) as run:\n",
    "        config = wandb.config\n",
    "        unet = UNet(3, dataset.len_categories, config).cuda()\n",
    "        optim = torch.optim.Adam(unet.parameters(), lr=config[\"lr\"])\n",
    "        bar = tqdm.tqdm(train_loader, leave=False)\n",
    "        for x in range(config[\"epochs\"]):\n",
    "            for data in bar:\n",
    "                optim.zero_grad()\n",
    "                segmask = unet(data.images.cuda())\n",
    "                loss = loss_fn(segmask, data.masks.cuda().long())\n",
    "                loss.backward()\n",
    "                bar.set_description(\"Loss: %f\" % loss.detach().cpu())\n",
    "                wandb.log({\"loss\": loss.detach().cpu()})\n",
    "                optim.step()\n",
    "        test_bar = tqdm.tqdm(test_loader, leave=False)\n",
    "        with torch.no_grad():\n",
    "            for data in test_bar:\n",
    "                segmask = unet(data.images.cuda())\n",
    "                mask = torch.argmax(segmask, dim=1).detach().squeeze()\n",
    "                acc = pixel_accuracy(mask, segmask)\n",
    "                wandb.log({\"pixacc\": acc})\n",
    "        # Draw one sample and visualize the mask for each sweep\n",
    "        sample = test_dataset[0]\n",
    "        segmask = unet(sample.image.unsqueeze(0).cuda())\n",
    "        mask = torch.argmax(segmask, dim=1).detach().squeeze()\n",
    "        viz_mask(sample.image, mask, sample.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dabe990a",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d3f95175",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l5hpwmjo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: ReLU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbilinear: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.008043417664695626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunet_channels: 32\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adrishd/taco-baseline/runs/l5hpwmjo\" target=\"_blank\">frosty-sweep-2</a></strong> to <a href=\"https://wandb.ai/adrishd/taco-baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/adrishd/taco-baseline/sweeps/cmd01r6y\" target=\"_blank\">https://wandb.ai/adrishd/taco-baseline/sweeps/cmd01r6y</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 3.820595:  10%|█         | 12/120 [00:11<00:59,  1.81it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n",
      "                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3335... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>██▇▇▆▅▅▄▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>3.8206</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">frosty-sweep-2</strong>: <a href=\"https://wandb.ai/adrishd/taco-baseline/runs/l5hpwmjo\" target=\"_blank\">https://wandb.ai/adrishd/taco-baseline/runs/l5hpwmjo</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211207_204619-l5hpwmjo/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = 5 # Run 5 sweeps\n",
    "wandb.agent(\n",
    "    sweep_id,\n",
    "    function=train,\n",
    "    count=count\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7477584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

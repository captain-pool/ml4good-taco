{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023daf20",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "1634f85b",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install -Uq wandb tqdm torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad102b5",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6372256b",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "# Define wandb username, project name and dataset path\n",
    "wandb_username = \"adrishd\"\n",
    "wandb_project = \"taco-baseline\"\n",
    "dataset_artifact = 'adrishd/taco/taco:pytorch'\n",
    "\n",
    "# Downloading dataset\n",
    "# use root parameter in artifacts.download(root=<custom_path>)\n",
    "# to specify download directory. else download in the current directory.\n",
    "with wandb.init(entity=wandb_username, project=wandb_project) as run:\n",
    "    artifact = run.use_artifact(dataset_artifact, type='dataset')\n",
    "    artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401bac03",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "da2bbbb8",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "import tacoloader\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import torchsummary\n",
    "import time\n",
    "import tqdm\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e12965",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "bad56fb3",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "h, w, c = 512, 512, 3 # height, width and channel of images\n",
    "# Use torchvision.transpose.Compose to compose multiple transformations\n",
    "# together. Refer to: https://pytorch.org/vision/stable/transforms.html\n",
    "transform = torchvision.transforms.Resize(\n",
    "    (h, w),\n",
    "    torchvision.transforms.InterpolationMode.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ec03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants in the training pipeline\n",
    "train_batch_size = 10\n",
    "test_batch_size = 1\n",
    "split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990277a7",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9393e7f7",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset, collate_fn = tacoloader.load_dataset(artifact_dir, tacoloader.Environment.TORCH, transform_fn=transform)\n",
    "# Splitting Dataset to 80%-20% for training and testing\n",
    "dataset_size = len(dataset)\n",
    "indices = range(dataset_size)\n",
    "train_indices = indices[:int(split * dataset_size)]\n",
    "test_indices = indices[int(split * dataset_size) + 1:]\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad6166",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "02387601",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    collate_fn=dataset.collate_fn,\n",
    "    num_workers=6,\n",
    "    shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    collate_fn=dataset.collate_fn,\n",
    "    num_workers=6,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94686ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_mask(image, pred_mask, true_mask):\n",
    "    # Visualize segmentation mask on W&B dashboard\n",
    "    # image: torch tensor of dim [c, h, w]\n",
    "    # pred_mask: detached torch tensor of dim [h, w]\n",
    "    # true_mask: torch tensor of dim [h, w]\n",
    "    pred_labels = torch.unique(pred_mask).cpu().numpy().tolist()\n",
    "    predicted_class_labels = {\n",
    "        i : x for i, x in enumerate(dataset.get_categories(pred_labels))\n",
    "    }\n",
    "    gt_labels = torch.unique(true_mask).cpu().numpy().tolist()\n",
    "    ground_truth_labels = {\n",
    "        i: x for i, x in enumerate(dataset.get_categories(gt_labels))\n",
    "    }\n",
    "    wandb_image = wandb.Image(image.cpu(), masks={\n",
    "        \"prediction\": {\n",
    "            \"mask_data\": pred_mask.squeeze().cpu().numpy(),\n",
    "            \"class_labels\": predicted_class_labels\n",
    "        },\n",
    "        \"ground_truth\": {\n",
    "            \"mask_data\": true_mask.cpu().numpy(),\n",
    "            \"class_labels\": ground_truth_labels\n",
    "        }\n",
    "    })\n",
    "    wandb.log({\"semantic_segmentation\" : wandb_image})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec29abd",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "4fbc8a46",
     "kernelId": ""
    }
   },
   "source": [
    "## Model Design and Implementations\n",
    "### Starter Code: Helper Modules for UNet Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b853fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for getting activation functions\n",
    "# from torch.nn given the function name.\n",
    "# activations with inplace operations, are enabled\n",
    "# by default.\n",
    "import inspect\n",
    "import functools\n",
    "def get_activation_fn(fn_name):\n",
    "    fn = getattr(torch.nn, fn_name)\n",
    "    isinplace = \"inplace\" in inspect.signature(fn).parameters\n",
    "    if isinplace:\n",
    "        fn = functools.partial(fn, inplace=True)\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e18bae",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "432f3df7",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dummy baseline UNet model based on:\n",
    "# https://github.com/xiaopeng-liao/Pytorch-UNet/blob/master/unet/unet_parts.py\n",
    "class double_conv(torch.nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch, activation_fn_name):\n",
    "        super(double_conv, self).__init__()\n",
    "        activation_fn = get_activation_fn(activation_fn_name)\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            torch.nn.BatchNorm2d(out_ch),\n",
    "            activation_fn(),\n",
    "            torch.nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            torch.nn.BatchNorm2d(out_ch),\n",
    "            activation_fn()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class inconv(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation_fn):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch, activation_fn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class down(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation_fn):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            double_conv(in_ch, out_ch, activation_fn)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class up(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation_fn, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "        if bilinear:\n",
    "            self.up = torch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = torch.nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch, activation_fn)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffX = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
    "                        diffY // 2, diffY - diffY//2))\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class outconv(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_ch, out_ch, 1)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5350994",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f53a7046",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, config):\n",
    "        super(UNet, self).__init__()\n",
    "        mid_channels = config[\"unet_channels\"]\n",
    "        activation_fn = config[\"activation_fn\"]\n",
    "        self.inc = inconv(n_channels,\n",
    "                          mid_channels,\n",
    "                          activation_fn)\n",
    "        self.down1 = down(mid_channels,\n",
    "                          mid_channels * 2,\n",
    "                          activation_fn)\n",
    "        self.down2 = down(mid_channels * 2,\n",
    "                          mid_channels * 4,\n",
    "                          activation_fn)\n",
    "        self.down3 = down(mid_channels * 4,\n",
    "                          mid_channels * 8,\n",
    "                          activation_fn)\n",
    "        self.down4 = down(mid_channels * 8,\n",
    "                          mid_channels * 8,\n",
    "                          activation_fn)\n",
    "        self.up1 = up(mid_channels * 16,\n",
    "                      mid_channels * 4,\n",
    "                      activation_fn,\n",
    "                      bilinear=config[\"bilinear\"])\n",
    "        self.up2 = up(mid_channels * 8,\n",
    "                      mid_channels * 2,\n",
    "                      activation_fn,\n",
    "                      bilinear=config[\"bilinear\"])\n",
    "        self.up3 = up(mid_channels * 4,\n",
    "                      mid_channels,\n",
    "                      activation_fn,\n",
    "                      bilinear=config[\"bilinear\"])\n",
    "        self.up4 = up(mid_channels * 2,\n",
    "                      mid_channels,\n",
    "                      activation_fn,\n",
    "                      bilinear=config[\"bilinear\"])\n",
    "        self.outc = outconv(mid_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ea046",
   "metadata": {
    "gradient": {
     "id": "d72b2488",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565a9f90",
   "metadata": {},
   "source": [
    "### Training, Logging, Finding Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using wandb's hyperparameter optimization framework sweeps\n",
    "# More information can be found here: https://docs.wandb.ai/guides/sweeps\n",
    "sweep_config = {\n",
    "    \"name\" : \"sweep-params\",\n",
    "    \"method\" : \"random\",\n",
    "    \"parameters\" : {\n",
    "        \"epochs\" : {\n",
    "            \"values\": [0, 1]\n",
    "        },\n",
    "        \"lr\" : {\n",
    "            \"min\": 1e-4,\n",
    "            \"max\": 1e-2\n",
    "        },\n",
    "        \"activation_fn\" : {\n",
    "            \"values\" : [\"ReLU\", \"LeakyReLU\", \"PReLU\"]\n",
    "        },\n",
    "        \"unet_channels\" : {\n",
    "            \"values\" : [8, 16, 32]\n",
    "        },\n",
    "        \"bilinear\" : {\n",
    "            \"values\" : [True, False]\n",
    "        },\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(\n",
    "    sweep_config,\n",
    "    entity=wandb_username,\n",
    "    project=wandb_project\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e549df7",
   "metadata": {
    "gradient": {
     "id": "93b7c0b2",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    with wandb.init(entity=wandb_username, project=wandb_project) as run:\n",
    "        config = wandb.config\n",
    "        unet = UNet(3, dataset.len_categories, config).cuda()\n",
    "        optim = torch.optim.Adam(unet.parameters(), lr=config[\"lr\"])\n",
    "        bar = tqdm.tqdm(train_loader, leave=False)\n",
    "        for x in range(config[\"epochs\"]):\n",
    "            for data in bar:\n",
    "                optim.zero_grad()\n",
    "                segmask = unet(data.images.cuda())\n",
    "                loss = loss_fn(segmask, data.masks.cuda().long())\n",
    "                loss.backward()\n",
    "                bar.set_description(\"Loss: %f\" % loss.detach().cpu())\n",
    "                wandb.log({\"loss\": loss.detach().cpu()})\n",
    "                optim.step()\n",
    "        # Draw one sample and visualize the mask for each sweep\n",
    "        sample = test_dataset[0]\n",
    "        segmask = unet(sample.image.unsqueeze(0).cuda())\n",
    "        mask = torch.argmax(segmask, dim=1).detach().squeeze()\n",
    "        viz_mask(sample.image, mask, sample.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029605d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 5 # Run 5 sweeps\n",
    "wandb.agent(\n",
    "    sweep_id,\n",
    "    function=train,\n",
    "    count=count\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
